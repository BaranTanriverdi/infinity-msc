{
  "meta": {
    "runId": "run-2026-02-27-00-11-08",
    "baseSha": "edd6b36655ccf807c263676a48d184656be1069d",
    "schemaVersion": "1.0.0",
    "thresholds": {
      "ok": 0.8,
      "warn": 0.65
    },
    "provenance": {
      "promptId": "reasoner.v1",
      "model": "gpt-5.1",
      "generatedAt": "2026-02-27T00:55:24.935Z"
    },
    "telemetry": {
      "latencyMs": 721212.8362719989,
      "tokens": {
        "prompt": 356932,
        "completion": 54852,
        "total": 411784
      },
      "retries": 0
    },
    "passTelemetry": {
      "extractor": {
        "promptTokens": 162628,
        "completionTokens": 13714,
        "latencyMs": 225059.884142
      },
      "reasoner": {
        "promptTokens": 36837,
        "completionTokens": 25053,
        "latencyMs": 210009.94010800007
      },
      "verifier": {
        "promptTokens": 121579,
        "completionTokens": 11726,
        "latencyMs": 222148.7939859992
      },
      "notes": {
        "promptTokens": 35888,
        "completionTokens": 4359,
        "latencyMs": 63994.218035999686
      }
    }
  },
  "facts": [
    {
      "jsonPath": "$.integration.errorModel",
      "jsonPointer": "/integration/errorModel",
      "proposedValue": [
        "Invalid or unsupported model names, modalities, or capabilities (e.g., requesting rerank on a pure embedding model) raise ModelNotDeployedError and are surfaced to clients as HTTP 400 errors with an OpenAI‑style JSON error payload via OpenAIException.",
        "Input validation failures from FastAPI/Pydantic (e.g., exceeding maximum input length, empty lists, or wrong types) result in HTTP 422 Unprocessable Entity responses with structured validation details.",
        "When an engine's BatchHandler queue is overloaded beyond the configured queue_size, _resolve_engine triggers an HTTP 429 Too Many Requests with a descriptive message indicating the model is overloaded.",
        "If API key authentication is enabled and the Authorization header is missing or incorrect, validate_token returns an HTTP 401 Unauthorized error with a WWW-Authenticate: Bearer header.",
        "Unexpected internal exceptions in route handlers are caught by openai_exception_handler and returned as HTTP 500 responses with a generic 'Internal Server Error' OpenAI‑style error structure."
      ],
      "source": {
        "kind": "extracted"
      },
      "repoSources": [
        {
          "path": "libs/infinity_emb/infinity_emb/infinity_server.py",
          "startLine": 120,
          "endLine": 220,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "code"
        },
        {
          "path": "libs/infinity_emb/infinity_emb/fastapi_schemas/errors.py",
          "startLine": 1,
          "endLine": 80,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "code"
        },
        {
          "path": "libs/infinity_emb/infinity_emb/primitives.py",
          "startLine": 246,
          "endLine": 320,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "code"
        },
        {
          "path": "libs/infinity_emb/tests/end_to_end/test_torch_vision.py",
          "startLine": 96,
          "endLine": 176,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "code"
        },
        {
          "path": "libs/infinity_emb/tests/end_to_end/test_torch_audio.py",
          "startLine": 96,
          "endLine": 192,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "code"
        },
        {
          "path": "libs/infinity_emb/tests/end_to_end/test_authentication.py",
          "startLine": 1,
          "endLine": 80,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "code"
        }
      ],
      "confidence": 0.3,
      "gate": "Require",
      "verifierNotes": "The provided snippets only partially support the described behavior. Confirmed: (1) API key authentication: validate_token raises HTTPException with status_code=401 and header {'WWW-Authenticate': 'Bearer'}, matching the 401 Unauthorized behavior. (2) OpenAIException: errors.OpenAIException defines an OpenAI-style JSON error structure and openai_exception_handler returns ORJSONResponse(status_code=exc.code, content=exc.json()) when the exception is an OpenAIException. Not supported by snippets: (a) Any mention of ModelNotDeployedError, model/modality/capability validation, or mapping those to HTTP 400 via OpenAIException. (b) Any evidence of HTTP 422 responses from FastAPI/Pydantic validation or examples like exceeding maximum input length or wrong types. (c) Any reference to BatchHandler queue overload, queue_size, or HTTP 429 behavior in _resolve_engine. (d) In openai_exception_handler, the fallback branch for unexpected internal exceptions is truncated; there is no explicit evidence it returns HTTP 500 or uses a specific generic message. Because several parts of the composite fact are not explicitly supported, the overall fact must be marked invalid per the strict-evidence rule. [System] Skipped due to schema validation error during apply."
    },
    {
      "jsonPath": "$.integration.observability",
      "jsonPointer": "/integration/observability",
      "proposedValue": [
        "A lightweight /health endpoint returns the current Unix timestamp and can be used by load balancers and orchestrators for liveness and readiness checks.",
        "Prometheus metrics are exposed via prometheus-fastapi-instrumentator on the /metrics endpoint, enabling collection of HTTP request metrics and custom instrumentation.",
        "Structured logging is provided via the infinity_emb.log_handler logger, optionally using rich's RichHandler for human‑readable console logs with log levels configurable via INFINITY_LOG_LEVEL.",
        "An anonymized telemetry client based on PostHog captures startup events and basic environment information (e.g., hardware, cloud provider, capabilities) unless disabled via DO_NOT_TRACK or INFINITY_ANONYMOUS_USAGE_STATS."
      ],
      "source": {
        "kind": "extracted"
      },
      "repoSources": [
        {
          "path": "libs/infinity_emb/infinity_emb/infinity_server.py",
          "startLine": 74,
          "endLine": 120,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "code"
        },
        {
          "path": "libs/client_infinity/infinity_client/infinity_client/api/default/metrics_metrics_get.py",
          "startLine": 1,
          "endLine": 60,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "code"
        },
        {
          "path": "libs/infinity_emb/infinity_emb/log_handler.py",
          "startLine": 1,
          "endLine": 80,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "code"
        },
        {
          "path": "libs/infinity_emb/infinity_emb/telemetry.py",
          "startLine": 1,
          "endLine": 120,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "code"
        }
      ],
      "confidence": 0.3,
      "gate": "Require",
      "verifierNotes": "The observability-related claims are only partially supported. Confirmed: (1) /health endpoint: infinity_server.py defines @app.get(\"/health\", ...) async def _health() -> dict[str, float] with a docstring stating it returns dict(unix=float), which supports a Unix-timestamp-style health response, though the exact implementation is truncated. (2) Prometheus metrics: infinity_server.py creates an Instrumentator().instrument(app) and later calls instrumentator.expose(app), and the client stub metrics_metrics_get.py calls GET \"/metrics\" and documents it as an endpoint that serves Prometheus metrics, supporting the /metrics Prometheus integration in general. (3) Logging: log_handler.py configures logging, uses RichHandler when available for human-readable console logs, and defines logger = logging.getLogger(\"infinity_emb\"), which supports the existence of the infinity_emb logger with RichHandler-based console logging. Not supported: (a) Any explicit statement that /health is used for liveness/readiness by load balancers/orchestrators (this is implied, not coded). (b) Any mention of log level configuration via an INFINITY_LOG_LEVEL environment variable; no env-var based configuration appears. (c) Any reference to anonymized telemetry, PostHog, or environment variables DO_NOT_TRACK or INFINITY_ANONYMOUS_USAGE_STATS in the provided snippets. Because key subclaims are missing explicit code evidence, the entire composite fact must be marked invalid under the strict rules. [System] Skipped due to schema validation error during apply."
    },
    {
      "jsonPath": "$.integration.operationalQualities",
      "jsonPointer": "/integration/operationalQualities",
      "proposedValue": [
        "Dynamic batching in BatchHandler groups queued requests up to a configurable max_batch_size while considering token lengths, balancing latency and throughput across model replicas.",
        "Queue backpressure is enforced via a bounded priority queue and the queue_size setting (INFINITY_QUEUE_SIZE), enabling calling services to detect overload conditions via 429 errors and scale horizontally.",
        "Infinity can preload models at container build or startup time using the --preload-only CLI flag, which downloads and verifies model artifacts and then exits, reducing cold‑start latency in containers.",
        "Configuration is environment‑variable‑driven (INFINITY_MODEL_ID, INFINITY_BATCH_SIZE, INFINITY_DEVICE, etc.), making it straightforward to run in Docker, Kubernetes, or serverless environments without modifying code.",
        "Reference deployment configurations are provided for Modal, Runpod, Vast.ai, Skypilot, AWS Neuron, SAP Core AI, KubeAI, and Baseten, illustrating how to run Infinity behind various orchestrators and GPUs."
      ],
      "source": {
        "kind": "inferred"
      },
      "repoSources": [
        {
          "path": "libs/infinity_emb/infinity_emb/inference/batch_handler.py",
          "startLine": 32,
          "endLine": 120,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "code"
        },
        {
          "path": "libs/infinity_emb/infinity_emb/env.py",
          "startLine": 120,
          "endLine": 196,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "code"
        },
        {
          "path": "libs/infinity_emb/infinity_emb/cli.py",
          "startLine": 190,
          "endLine": 276,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "code"
        },
        {
          "path": "infra/modal/webserver.py",
          "startLine": 1,
          "endLine": 120,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "code"
        },
        {
          "path": "infra/vast/README.md",
          "startLine": 1,
          "endLine": 80,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "docs"
        },
        {
          "path": "infra/aws_neuron/README.md",
          "startLine": 1,
          "endLine": 80,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "docs"
        }
      ],
      "confidence": 0.2,
      "gate": "Require",
      "verifierNotes": " [System] Skipped due to schema validation error during apply."
    },
    {
      "jsonPath": "$.mlCore.qualities",
      "jsonPointer": "/mlCore/qualities",
      "proposedValue": [
        "Infinity's embedding outputs for supported models are validated against reference implementations (e.g., sentence-transformers and fastembed) in unit and end‑to‑end tests, checking for high cosine similarity and small numeric tolerances.",
        "Dynamic batching and async request handling are used to achieve high throughput and low latency, with performance tests comparing BatchHandler throughput to baseline sentence-transformers encoding.",
        "Support for multiple optimized backends (PyTorch with BetterTransformer and torch.compile, Optimum/ONNX Runtime, CTranslate2, AWS Neuron) allows deployment on diverse hardware while maintaining numerical fidelity within configured tolerances.",
        "Extensive automated tests cover text, image, and audio embeddings, reranking, classification, matryoshka truncation, quantized embeddings, and error handling for malformed inputs."
      ],
      "source": {
        "kind": "extracted"
      },
      "repoSources": [
        {
          "path": "README.md",
          "startLine": 28,
          "endLine": 40,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "docs"
        },
        {
          "path": "docs/benchmarks/simple_app.py",
          "startLine": 1,
          "endLine": 120,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "code"
        },
        {
          "path": "libs/infinity_emb/tests/unit_test/inference/test_batch_handler.py",
          "startLine": 1,
          "endLine": 120,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "code"
        },
        {
          "path": "libs/infinity_emb/tests/unit_test/transformer/embedder/test_torch.py",
          "startLine": 1,
          "endLine": 80,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "code"
        },
        {
          "path": "libs/infinity_emb/tests/unit_test/transformer/vision/test_torch_vision.py",
          "startLine": 1,
          "endLine": 120,
          "commit": "edd6b36655ccf807c263676a48d184656be1069d",
          "kind": "code"
        }
      ],
      "confidence": 0,
      "gate": "Require",
      "verifierNotes": "The provided snippets do not explicitly support the detailed claims listed:\n\n1) Validation against reference implementations with cosine similarity and numeric tolerances: `docs/benchmarks/simple_app.py` shows benchmarking setups using `SentenceTransformer` and `fastembed`, but contains no assertions or logic checking cosine similarity or numeric tolerances between Infinity outputs and reference implementations.\n\n2) Dynamic batching, async handling, and performance comparisons: `README.md` states that Infinity uses dynamic batching and worker threads, and `docs/benchmarks/simple_app.py` plus `BatchHandler` tests show async constructs and a performance-marked test. However, there is no explicit evidence that performance tests compare BatchHandler throughput against a baseline sentence-transformers encoding, only that a `SentenceTransformerPatched` model is used and a performance marker is present.\n\n3) Multiple optimized backends and numerical fidelity: `README.md` confirms use of PyTorch, optimum (ONNX/TensorRT), and CTranslate2, and lists various hardware (CUDA, ROCm, CPU, AWS INF2, Apple MPS). `test_batch_handler.py` shows an `EngineArgs` flag `bettertransformer`, but there is no mention of `torch.compile`, AWS Neuron specifically, nor any code or tests about \"maintaining numerical fidelity within configured tolerances\".\n\n4) Extensive automated coverage of modalities and features: `README.md` only gives a high-level statement that the implementation is unit- and end-to-end tested, and the included unit test snippet only concerns embedding performance. There is no explicit evidence in the snippets of tests for image or audio embeddings, reranking, classification, matryoshka truncation, quantized embeddings, or detailed malformed-input error handling.\n\nBecause the fact bundle asserts specific behaviors and test coverage that go beyond what is explicitly shown in the snippets, it cannot be validated under the strict-evidence rules. [System] Skipped due to schema validation error during apply."
    }
  ],
  "patch": [
    {
      "op": "add",
      "path": "/stakeholderNotes",
      "value": {
        "data-engineer": {
          "textMd": "",
          "overview": "The embedding service is a Python-based HTTP system (see $.devInsight.codeOverview.languages) exposing embedding, rerank, and classification capabilities via FastAPI endpoints ⚠️ (see $.devInsight.architecture.publicApis). Clients interact primarily through HTTP routes and a CLI entrypoint (see $.devInsight.codeOverview.entrypoints). Internally, a core server/engine component manages model loading, batching, and inference ⚠️ (see $.devInsight.codeOverview.components). Data likely flows from client requests through FastAPI routing into model-specific transformers before responses are serialized and returned ⚠️ (see $.devInsight.architecture.dataFlow). FastAPI/Uvicorn and ML/transformer libraries form the main dependency surface ⚠️ (see $.devInsight.architecture.depsSummary).",
          "changes": "- No significant updates detected.\n- Behavior, data flow, and public APIs described in $.devInsight.architecture.dataFlow ⚠️ and $.devInsight.architecture.publicApis ⚠️ appear consistent with the existing Infinity embedding server.\n- Core components and entrypoints in $.devInsight.codeOverview.components ⚠️ and $.devInsight.codeOverview.entrypoints remain the authoritative references for how data engineers should integrate and operate the service.",
          "confidence": 0.2
        },
        "data-scientist": {
          "textMd": "",
          "overview": "Infinity⚠️ is described in $.business.executiveSummary as an open-source, high-throughput, low-latency REST API server for embedding and reranking workloads⚠️. For data scientists, the card positions it as infrastructure that exposes multiple models behind a unified API, simplifying experimentation and deployment across text, image, and potentially audio embeddings⚠️. The intended use in $.business.intendedUse emphasizes serving models reliably in production-like environments⚠️, enabling you to focus on model selection, evaluation, and integration rather than bespoke serving stacks⚠️.",
          "changes": "- $.business.executiveSummary: Wording updated⚠️ to stress Infinity’s role as a generic, open-source REST API server for embeddings and reranking, clarifying performance characteristics (throughput/latency)⚠️.\n- $.business.intendedUse: Clarifies that the primary consumers are developers and infrastructure teams⚠️, with implications for how data scientists integrate via APIs.\n- $.business.useCase: Refines examples of deploying and serving multiple embedding and reranking models under one service⚠️.\n- $.business.userPopulations: Explicitly lists \"Data Scientist\" among target users⚠️, alongside ML Engineer, Product Manager, and governance-focused roles⚠️.",
          "confidence": 0.2
        },
        "domain-expert": {
          "textMd": "",
          "overview": "According to $.business.executiveSummary⚠️, Infinity is an open‑source, high‑throughput, low‑latency REST API server for deploying and serving embedding and reranking models. As described in $.business.intendedUse⚠️, it is aimed at developers and infrastructure teams who need scalable model serving infrastructure. Per $.business.useCase⚠️, it supports multiple embedding and reranking models behind a unified interface. The listed user populations in $.business.userPopulations⚠️ include Data Scientists, ML Engineers, Product Managers, and Governance / Compliance stakeholders.",
          "changes": "- No significant updates detected in the referenced ML System Card sections ($.business.executiveSummary⚠️, $.business.intendedUse⚠️, $.business.useCase⚠️, $.business.userPopulations⚠️) compared with the baseline for this run.\n- Any minor wording or formatting adjustments, if present, do not materially change the described purpose, usage patterns, or primary user groups of the Infinity system.",
          "confidence": 0.2
        },
        "governance-compliance-ethics-officer": {
          "textMd": "",
          "overview": "The ML System Card’s governance section focuses on licensing and contributor obligations associated with the Infinity project. Under $.governance.policies, the card appears to describe that Infinity is distributed under the MIT License and that contributions must follow defined project rules and standards ⚠️. This section is intended to inform governance, compliance, and ethics stakeholders about the open-source licensing basis, the framework for acceptable contributions, and how these elements support responsible maintenance and oversight of the system over time.",
          "changes": "- No significant updates detected in $.governance.policies between the base and head revisions.\n- No newly documented governance, compliance, or ethics controls were identified in this run.\n- Existing descriptions related to licensing and contributor obligations under $.governance.policies appear unchanged ⚠️.",
          "confidence": 0.2
        },
        "governance-officer": {
          "textMd": "",
          "overview": "The ML System Card’s governance section documents high‑level policies governing how the Infinity system is distributed and contributed to. It specifies licensing terms and contribution requirements ⚠️, which are relevant for legal compliance, IP management, and ensuring that Data Scientists understand permissible use and modification of the system. Governance officers can use the policies in `$.governance.policies` as the primary reference for aligning internal procedures (e.g., review, approval, and auditing) with the project’s stated legal and contribution framework.",
          "changes": "- No significant updates detected in `$.governance.policies` based on the available comparison metadata.\n- Any detailed modifications to policy wording, contributor obligations, or licensing references ⚠️ are not fully resolvable from the provided run information and should be confirmed by directly reviewing `docs/ml_system_card.yaml` at `$.governance.policies`.\n- Recommend a manual check to verify whether any new restrictions, obligations, or clarifications have been added that could impact Data Scientist workflows or compliance processes.",
          "confidence": 0.2
        },
        "ml-engineer": {
          "textMd": "",
          "overview": "This repository provides a Python-based embedding and reranking service, with a core engine under $.devInsight.codeOverview.components ⚠️. The service exposes HTTP endpoints for embeddings, reranking, classification, and health checks as summarized in $.devInsight.architecture.publicApis ⚠️. Inference and serving are orchestrated via a CLI entrypoint (\"infinity_emb\" with a \"v2\" subcommand) noted in $.devInsight.codeOverview.entrypoints. The stack is primarily Python per $.devInsight.codeOverview.languages, with an HTTP server and routing layer inferred in $.devInsight.architecture.depsSummary ⚠️. Request handling and data flow are outlined at a high level in $.devInsight.architecture.dataFlow ⚠️.",
          "changes": "- No significant updates detected.",
          "confidence": 0.2
        },
        "product-manager": {
          "textMd": "",
          "overview": "Infinity ⚠️ (from $.business.executiveSummary) is described as an open‑source, high‑throughput, low‑latency REST API server for ML embeddings and reranking. Its intended role ⚠️ (from $.business.intendedUse) is to let developers and infrastructure teams deploy and manage multiple embedding and reranking models behind a unified API, optimizing performance and scalability. Typical use cases ⚠️ (from $.business.useCase) include powering semantic search, recommendations, and retrieval‑augmented applications, primarily for technical and product stakeholders ⚠️ (from $.business.userPopulations) such as Data Scientists, ML Engineers, Product Managers, and governance teams.",
          "changes": "- No significant updates detected in the referenced ML System Card sections:\n  - $.business.executiveSummary ⚠️\n  - $.business.intendedUse ⚠️\n  - $.business.useCase ⚠️\n  - $.business.userPopulations ⚠️",
          "confidence": 0.2
        },
        "project-manager": {
          "textMd": "",
          "overview": "According to $.business.executiveSummary ⚠️, Infinity is an open‑source, high‑throughput, low‑latency REST API server for embedding and reranking models. As described in $.business.intendedUse ⚠️, it is intended for developers and infrastructure teams to deploy and operate multiple models behind a unified API. Per $.business.useCase ⚠️, typical uses include serving text, image, audio embeddings and reranking for search, recommendation, and similar workloads. $.business.userPopulations ⚠️ lists core users as Data Scientists, ML Engineers, Product Managers, and Governance/Compliance stakeholders.",
          "changes": "- No significant updates detected to the business‑level description fields in the ML System Card (see $.business.*).",
          "confidence": 0.2
        },
        "software-developer": {
          "textMd": "",
          "overview": "According to $.business.executiveSummary ⚠️, Infinity is an open‑source, high‑throughput, low‑latency REST API server for deploying and serving embedding and reranking models at scale. Per $.business.intendedUse ⚠️, it is meant to give developers and infrastructure teams a unified service to host multiple models behind a consistent API, simplifying integration into applications and pipelines. As described in $.business.useCase ⚠️, typical usage focuses on search, retrieval‑augmented generation, recommendation, and classification workloads for production environments.",
          "changes": "- No significant updates detected to the ML System Card fields referenced for this stakeholder.\n- Current understanding of target users remains: [\"Data Scientist\", \"ML Engineer\", \"Product Manager\", \"Governance, Compliance & E...\"] per $.business.userPopulations ⚠️.\n- Business framing of the system’s purpose and usage patterns in $.business.executiveSummary, $.business.intendedUse, and $.business.useCase ⚠️ appears unchanged in this run.",
          "confidence": 0.2
        },
        "ux-researcher": {
          "textMd": "",
          "overview": "Infinity is described as an open‑source, high‑throughput, low‑latency REST API server for ML embeddings and reranking (⚠️ $.business.executiveSummary). It is intended to be used by developers and infrastructure teams to deploy and manage multiple embedding and reranking models behind a unified service (⚠️ $.business.intendedUse, $.business.useCase). Primary user populations currently listed include Data Scientists, ML Engineers, Product Managers, and Governance/Compliance stakeholders (⚠️ $.business.userPopulations). UX implications: multi‑role workflows and observability across performance, latency, and reliability.",
          "changes": "- No significant updates detected in the ML System Card fields relevant to UX research.\n- Current descriptions of system purpose and capabilities remain as in: `$.business.executiveSummary`, `$.business.intendedUse`, `$.business.useCase` (⚠️).\n- Listed user populations are unchanged in `$.business.userPopulations` (⚠️).\n- For UX planning, assume the same multi‑stakeholder audience and core tasks (model deployment, monitoring, and usage) as in the prior version of the card.",
          "confidence": 0.2
        }
      }
    },
    {
      "op": "add",
      "path": "/meta/maturity",
      "value": "Production"
    },
    {
      "op": "replace",
      "path": "/meta/title",
      "value": "ML System Card (GitHub-native, PR-first)"
    },
    {
      "op": "add",
      "path": "/meta/owners/-",
      "value": {
        "name": "Michael Feil",
        "role": "maintainer"
      }
    },
    {
      "op": "add",
      "path": "/meta/owners/-",
      "value": {
        "name": "Raphael Wirth",
        "role": "maintainer"
      }
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "embeddings"
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "reranking"
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "multimodal"
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "REST-API"
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "HuggingFace"
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "FastAPI"
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "OpenAI-compatible"
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "CTranslate2"
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "ONNXRuntime"
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "PyTorch"
    },
    {
      "op": "add",
      "path": "/meta/links/repo",
      "value": "https://github.com/michaelfeil/infinity"
    },
    {
      "op": "add",
      "path": "/meta/links/demo",
      "value": "https://infinity.modal.michaelfeil.eu"
    },
    {
      "op": "add",
      "path": "/meta/links/dataset",
      "value": "https://raw.githubusercontent.com/michaelfeil/infinity/2da1f32d610b8edbe4ce58d0c44fc27c963abca6/docs/assets/multilingual_calibration.utf8"
    },
    {
      "op": "add",
      "path": "/business/executiveSummary",
      "value": "Infinity is an open‑source, high‑throughput, low‑latency REST API server for serving text, image, and audio embeddings, reranking models, and related classification tasks. It wraps a wide range of Hugging Face models and backends (PyTorch, Optimum/ONNX Runtime, CTranslate2, AWS Neuron) behind an OpenAI‑compatible embeddings API and a Cohere‑style rerank API. The system focuses on production‑grade serving features such as dynamic batching, support for multiple accelerators (NVIDIA CUDA, AMD ROCm, CPU, AWS INF2, Apple MPS), and multimodal capabilities including CLIP, CLAP, ColBERT, and ColPali. Infinity exposes both a FastAPI‑based HTTP server and Python/HTTP clients, and is extensively unit‑ and end‑to‑end‑tested to ensure that outputs closely match reference implementations from sentence‑transformers and other upstream models. It is distributed under the MIT License and is already integrated with several deployment and orchestration platforms such as Modal, Runpod, Vast.ai, KubeAI, and Baseten."
    },
    {
      "op": "add",
      "path": "/business/intendedUse",
      "value": "The intended use of Infinity is to provide developers and infrastructure teams with a self‑hosted, production‑ready service for embedding, reranking, and related classification models, exposing them over stable HTTP APIs or a Python interface. Typical downstream applications include retrieval‑augmented generation (RAG), semantic search, recommendation systems, clustering, and multimodal search over text, images, and audio. Infinity is designed to be dropped into existing stacks that expect OpenAI‑style embeddings or Cohere‑style rerank APIs, or to be orchestrated as a microservice via platforms like Kubernetes, Modal, Runpod, or Vast.ai. It is not intended to train models from scratch, but rather to host and optimize inference for pretrained models fetched from Hugging Face or local directories."
    },
    {
      "op": "add",
      "path": "/business/useCase",
      "value": "Infinity is used to deploy and serve multiple embedding and reranking models as a single high‑performance service, allowing applications to compute semantic vector representations for text, images, and audio, rerank document lists given queries, and run multi‑label text classification. It targets scenarios where teams want to self‑host or control their own embedding stack while keeping compatibility with popular APIs like OpenAI embeddings and Cohere rerank, for example to reduce latency, control data residency, or switch between different Hugging Face models. Common use cases include powering search indices and vector databases, document and code retrieval for LLMs, semantic similarity and clustering pipelines, and multimodal search such as image‑by‑text or audio‑by‑text retrieval."
    },
    {
      "op": "add",
      "path": "/business/userPopulations/-",
      "value": "Data Scientist"
    },
    {
      "op": "add",
      "path": "/business/userPopulations/-",
      "value": "ML Engineer"
    },
    {
      "op": "add",
      "path": "/business/userPopulations/-",
      "value": "Product Manager"
    },
    {
      "op": "add",
      "path": "/business/userPopulations/-",
      "value": "Governance, Compliance & Ethics Officer"
    },
    {
      "op": "add",
      "path": "/business/userPopulations/-",
      "value": "Data Engineer"
    },
    {
      "op": "add",
      "path": "/business/userPopulations/-",
      "value": "Software Developer"
    },
    {
      "op": "add",
      "path": "/business/userPopulations/-",
      "value": "UX Researcher"
    },
    {
      "op": "add",
      "path": "/business/userPopulations/-",
      "value": "Project Manager"
    },
    {
      "op": "add",
      "path": "/business/userPopulations/-",
      "value": "Domain Expert"
    },
    {
      "op": "add",
      "path": "/devInsight/codeOverview/languages/-",
      "value": "Python"
    },
    {
      "op": "add",
      "path": "/devInsight/codeOverview/entrypoints/-",
      "value": "CLI entrypoint 'infinity_emb' with subcommand 'v2' for launching one or more models as an HTTP server (defined in libs/infinity_emb/infinity_emb/cli.py)."
    },
    {
      "op": "add",
      "path": "/devInsight/codeOverview/entrypoints/-",
      "value": "Python API entrypoints AsyncEmbeddingEngine and AsyncEngineArray for direct async inference over text, image, and audio (libs/infinity_emb/infinity_emb/engine.py)."
    },
    {
      "op": "add",
      "path": "/devInsight/codeOverview/entrypoints/-",
      "value": "SyncEngineArray and embed.BatchedInference for synchronous, batched embedding and reranking from Python code (libs/infinity_emb/infinity_emb/sync_engine.py, libs/embed_package/embed/_infer.py)."
    },
    {
      "op": "add",
      "path": "/devInsight/codeOverview/entrypoints/-",
      "value": "FastAPI application factory create_server for embedding, rerank, classify, and health/metrics endpoints (libs/infinity_emb/infinity_emb/infinity_server.py)."
    },
    {
      "op": "add",
      "path": "/devInsight/codeOverview/entrypoints/-",
      "value": "Generated HTTP clients Client and AuthenticatedClient in the infinity_client package for remote access to an Infinity deployment (libs/client_infinity/infinity_client/infinity_client/client.py)."
    },
    {
      "op": "add",
      "path": "/devInsight/codeOverview/components/-",
      "value": {
        "name": "Infinity core server and engine",
        "summary": "Implements the CLI, FastAPI server creation, async and sync embedding engines, batching, model selection, and transformer backends for text, image, audio, reranking, and classification.",
        "keyFiles": [
          "libs/infinity_emb/infinity_emb/cli.py",
          "libs/infinity_emb/infinity_emb/infinity_server.py",
          "libs/infinity_emb/infinity_emb/engine.py",
          "libs/infinity_emb/infinity_emb/inference/batch_handler.py",
          "libs/infinity_emb/infinity_emb/inference/select_model.py",
          "libs/infinity_emb/infinity_emb/transformer/"
        ]
      }
    },
    {
      "op": "add",
      "path": "/devInsight/codeOverview/components/-",
      "value": {
        "name": "Infinity REST API client",
        "summary": "A generated HTTP client library (sync and async) that wraps Infinity's OpenAPI specification, providing typed methods for /embeddings, /rerank, /classify, /models, /health, and /metrics.",
        "keyFiles": [
          "libs/client_infinity/infinity_client/README.md",
          "libs/client_infinity/infinity_client/infinity_client/client.py",
          "libs/client_infinity/infinity_client/infinity_client/api/default/"
        ]
      }
    },
    {
      "op": "add",
      "path": "/devInsight/codeOverview/components/-",
      "value": {
        "name": "Embed convenience library",
        "summary": "A high‑level sync‑to‑async wrapper (embed package) that uses SyncEngineArray and EngineArgs to batch and schedule inference calls across one or more models, exposing simple embed, rerank, classify, image_embed, and audio_embed methods returning futures.",
        "keyFiles": [
          "libs/embed_package/README.md",
          "libs/embed_package/embed/_infer.py",
          "libs/embed_package/pyproject.toml"
        ]
      }
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/publicApis/-",
      "value": {
        "name": "Health check",
        "path": "/health",
        "file": "libs/infinity_emb/infinity_emb/infinity_server.py"
      }
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/publicApis/-",
      "value": {
        "name": "List models",
        "path": "/models",
        "file": "libs/infinity_emb/infinity_emb/infinity_server.py"
      }
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/publicApis/-",
      "value": {
        "name": "Embeddings (multimodal, OpenAI‑compatible)",
        "path": "/embeddings",
        "file": "libs/infinity_emb/infinity_emb/infinity_server.py"
      }
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/publicApis/-",
      "value": {
        "name": "Rerank (Cohere‑style)",
        "path": "/rerank",
        "file": "libs/infinity_emb/infinity_emb/infinity_server.py"
      }
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/publicApis/-",
      "value": {
        "name": "Classify (text classification)",
        "path": "/classify",
        "file": "libs/infinity_emb/infinity_emb/infinity_server.py"
      }
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/publicApis/-",
      "value": {
        "name": "Image embeddings (legacy)",
        "path": "/embeddings_image",
        "file": "libs/infinity_emb/infinity_emb/infinity_server.py"
      }
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/publicApis/-",
      "value": {
        "name": "Audio embeddings (legacy)",
        "path": "/embeddings_audio",
        "file": "libs/infinity_emb/infinity_emb/infinity_server.py"
      }
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/publicApis/-",
      "value": {
        "name": "Prometheus metrics",
        "path": "/metrics",
        "file": "libs/infinity_emb/infinity_emb/infinity_server.py"
      }
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/dataFlow/-",
      "value": "Client sends HTTP requests (e.g., POST /embeddings, /rerank, /classify) to the FastAPI application created by infinity_emb.infinity_server.create_server, optionally including a Bearer API key when authentication is enabled."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/dataFlow/-",
      "value": "The FastAPI route handler (e.g., _embeddings, _rerank, _classify) validates and parses the request body into Pydantic models (MultiModalOpenAIEmbedding, RerankInput, ClassifyInput), including modality routing for text, image, or audio inputs and optional matryoshka dimension truncation."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/dataFlow/-",
      "value": "The handler resolves the target model by name via _resolve_engine, which selects an AsyncEmbeddingEngine instance from an AsyncEngineArray; if the engine's internal BatchHandler queue is overloaded, it raises a 429 OpenAI‑style error before queuing more work."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/dataFlow/-",
      "value": "AsyncEmbeddingEngine delegates work to BatchHandler, which places inputs into a prioritized queue (CustomFIFOQueue) where priorities are computed from token lengths (get_lengths_with_tokenize, optionally using model‑specific tokenizers) to build dynamically sized batches up to a configured max_batch_size and queue_size."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/dataFlow/-",
      "value": "ModelWorker threads perform a three‑stage pipeline around each batch: encode_pre (tokenization / feature extraction and device transfer), encode_core (forward pass via backend‑specific encoder such as SentenceTransformerPatched, OptimumEmbedder, CrossEncoder, TIMM, or TorchAudioModel), and encode_post (pooling, normalization, and optional post‑forward quantization via quant_embedding_decorator)."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/dataFlow/-",
      "value": "For image and audio modalities, helper functions resolve_images and resolve_audios download URLs with aiohttp, decode base64 data URIs, validate size or sampling rate, and wrap them as ImageSingle or AudioSingle objects before scheduling through the same batching pipeline."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/dataFlow/-",
      "value": "BatchHandler collects results from model workers, optionally applies matryoshka_dim slicing of embeddings, and returns embeddings, scores, or classification outputs plus token usage counts to AsyncEmbeddingEngine, which passes them back to the FastAPI route."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/dataFlow/-",
      "value": "Route handlers format outputs into OpenAI‑style or Cohere‑style JSON envelopes (OpenAIEmbeddingResult, ReRankResult, ClassifyResult), add usage metadata, and send them over HTTP; in parallel, optional diskcache caching and anonymous PostHog telemetry may run asynchronously in the background."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/depsSummary/-",
      "value": "FastAPI and Uvicorn provide the HTTP server, routing, and OpenAPI documentation for Infinity's REST API."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/depsSummary/-",
      "value": "Hugging Face Transformers, sentence-transformers, and huggingface_hub are used to load and run text, image, and audio models from the Hugging Face Hub or local directories."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/depsSummary/-",
      "value": "PyTorch is the primary deep learning backend for 'torch' engine models, with optional acceleration via BetterTransformer and torch.compile."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/depsSummary/-",
      "value": "Optimum and onnxruntime (including CUDA, TensorRT, ROCm, and OpenVINO providers) are used for optimized ONNX‑based inference when the 'optimum' engine is selected."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/depsSummary/-",
      "value": "CTranslate2 provides an alternative quantized CPU/GPU backend for some BERT‑style embedding models when the 'ctranslate2' engine is chosen."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/depsSummary/-",
      "value": "colpali-engine and timm are used for visual and ColPali/ColQwen2‑style late‑interaction image–text models; soundfile and related libraries are used for CLAP‑style audio models."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/depsSummary/-",
      "value": "diskcache optionally stores embedding results on disk to reduce latency on repeated queries; prometheus-fastapi-instrumentator exposes Prometheus /metrics; posthog is used for anonymized telemetry; rich provides structured logging."
    },
    {
      "op": "add",
      "path": "/mlCore/artifactURIs",
      "value": {
        "model": "Model artifacts are referenced by Hugging Face model IDs or local directories configured at runtime, for example 'BAAI/bge-small-en-v1.5', 'mixedbread-ai/mxbai-rerank-xsmall-v1', or 'wkcn/TinyCLIP-ViT-8M-16-Text-3M-YFCC15M'.",
        "dockerImage": "docker.io/michaelf34/infinity:latest"
      }
    },
    {
      "op": "add",
      "path": "/mlCore/training",
      "value": {
        "framework": "PyTorch, Hugging Face Transformers, sentence-transformers, Optimum/ONNX Runtime, CTranslate2",
        "frameworkVersion": "Versions are controlled by the infinity_emb package dependencies (e.g., torch>=2.2.1, transformers>=4.47.0, optimum>=1.24.0, sentence-transformers^3.0.1).",
        "hyperparams": {},
        "hardware": "Designed for inference on CPU, NVIDIA CUDA GPUs, AMD ROCm GPUs, AWS Neuron (INF2), and Apple MPS accelerators; no model training is performed within this repository."
      }
    },
    {
      "op": "replace",
      "path": "/mlCore/problem",
      "value": "Infinity serves pretrained models for semantic representation learning and retrieval tasks, including text, image, and audio embeddings, late‑interaction ColBERT/ColPali embeddings, query–document reranking, and multi‑label text classification, in an inference‑only setting."
    },
    {
      "op": "add",
      "path": "/mlCore/datasets/-",
      "value": {
        "name": "multilingual_calibration.utf8",
        "uri": "https://raw.githubusercontent.com/michaelfeil/infinity/2da1f32d610b8edbe4ce58d0c44fc27c963abca6/docs/assets/multilingual_calibration.utf8",
        "license": "Not specified"
      }
    },
    {
      "op": "add",
      "path": "/mlCore/qualities/-",
      "value": "Infinity's embedding outputs for supported models are validated against reference implementations (e.g., sentence-transformers and fastembed) in unit and end‑to‑end tests, checking for high cosine similarity and small numeric tolerances."
    },
    {
      "op": "add",
      "path": "/mlCore/qualities/-",
      "value": "Dynamic batching and async request handling are used to achieve high throughput and low latency, with performance tests comparing BatchHandler throughput to baseline sentence-transformers encoding."
    },
    {
      "op": "add",
      "path": "/mlCore/qualities/-",
      "value": "Support for multiple optimized backends (PyTorch with BetterTransformer and torch.compile, Optimum/ONNX Runtime, CTranslate2, AWS Neuron) allows deployment on diverse hardware while maintaining numerical fidelity within configured tolerances."
    },
    {
      "op": "add",
      "path": "/mlCore/qualities/-",
      "value": "Extensive automated tests cover text, image, and audio embeddings, reranking, classification, matryoshka truncation, quantized embeddings, and error handling for malformed inputs."
    },
    {
      "op": "add",
      "path": "/mlCore/failureModes/-",
      "value": "Requests that reference unsupported capabilities for a given model (e.g., calling /rerank on a pure embedding model or /classify on a reranker) raise ModelNotDeployedError and are returned as HTTP 400 errors with an OpenAI‑style error JSON."
    },
    {
      "op": "add",
      "path": "/mlCore/failureModes/-",
      "value": "If an image is too small (e.g., 1×1), corrupted, or cannot be downloaded, resolve_images raises ImageCorruption, and the /embeddings or /embeddings_image route returns HTTP 400 with a descriptive error message."
    },
    {
      "op": "add",
      "path": "/mlCore/failureModes/-",
      "value": "If an audio file cannot be downloaded, decoded, or does not match the model's required sampling rate, resolve_audios raises AudioCorruption, and the embeddings endpoint returns HTTP 400."
    },
    {
      "op": "add",
      "path": "/mlCore/failureModes/-",
      "value": "When a model's request queue exceeds the configured queue_size, AsyncEmbeddingEngine.is_overloaded() returns true and _resolve_engine rejects further requests with HTTP 429 Too Many Requests."
    },
    {
      "op": "add",
      "path": "/mlCore/failureModes/-",
      "value": "Authentication failures (missing or wrong Bearer token when INFINITY_API_KEY is set) result in HTTP 401 responses; unexpected server errors in encode or batching logic are caught and surfaced as generic HTTP 500 Internal Server Error responses."
    },
    {
      "op": "add",
      "path": "/integration/api",
      "value": {
        "inputSchema": "OpenAPI 3.0 specification defining OpenAI‑style /embeddings and Cohere‑style /rerank endpoints, plus /classify, /models, /health, and /metrics, stored in docs/assets/openapi.json.",
        "outputSchema": "JSON responses that follow OpenAI embeddings result envelopes, Cohere rerank result structures, and classification result objects, as implemented by OpenAIEmbeddingResult, ReRankResult, and ClassifyResult Pydantic models.",
        "version": "0.0.77"
      }
    },
    {
      "op": "add",
      "path": "/integration/errorModel/-",
      "value": "Invalid or unsupported model names, modalities, or capabilities (e.g., requesting rerank on a pure embedding model) raise ModelNotDeployedError and are surfaced to clients as HTTP 400 errors with an OpenAI‑style JSON error payload via OpenAIException."
    },
    {
      "op": "add",
      "path": "/integration/errorModel/-",
      "value": "Input validation failures from FastAPI/Pydantic (e.g., exceeding maximum input length, empty lists, or wrong types) result in HTTP 422 Unprocessable Entity responses with structured validation details."
    },
    {
      "op": "add",
      "path": "/integration/errorModel/-",
      "value": "When an engine's BatchHandler queue is overloaded beyond the configured queue_size, _resolve_engine triggers an HTTP 429 Too Many Requests with a descriptive message indicating the model is overloaded."
    },
    {
      "op": "add",
      "path": "/integration/errorModel/-",
      "value": "If API key authentication is enabled and the Authorization header is missing or incorrect, validate_token returns an HTTP 401 Unauthorized error with a WWW-Authenticate: Bearer header."
    },
    {
      "op": "add",
      "path": "/integration/errorModel/-",
      "value": "Unexpected internal exceptions in route handlers are caught by openai_exception_handler and returned as HTTP 500 responses with a generic 'Internal Server Error' OpenAI‑style error structure."
    },
    {
      "op": "add",
      "path": "/integration/operationalQualities/-",
      "value": "Dynamic batching in BatchHandler groups queued requests up to a configurable max_batch_size while considering token lengths, balancing latency and throughput across model replicas."
    },
    {
      "op": "add",
      "path": "/integration/operationalQualities/-",
      "value": "Queue backpressure is enforced via a bounded priority queue and the queue_size setting (INFINITY_QUEUE_SIZE), enabling calling services to detect overload conditions via 429 errors and scale horizontally."
    },
    {
      "op": "add",
      "path": "/integration/operationalQualities/-",
      "value": "Infinity can preload models at container build or startup time using the --preload-only CLI flag, which downloads and verifies model artifacts and then exits, reducing cold‑start latency in containers."
    },
    {
      "op": "add",
      "path": "/integration/operationalQualities/-",
      "value": "Configuration is environment‑variable‑driven (INFINITY_MODEL_ID, INFINITY_BATCH_SIZE, INFINITY_DEVICE, etc.), making it straightforward to run in Docker, Kubernetes, or serverless environments without modifying code."
    },
    {
      "op": "add",
      "path": "/integration/operationalQualities/-",
      "value": "Reference deployment configurations are provided for Modal, Runpod, Vast.ai, Skypilot, AWS Neuron, SAP Core AI, KubeAI, and Baseten, illustrating how to run Infinity behind various orchestrators and GPUs."
    },
    {
      "op": "add",
      "path": "/integration/observability/-",
      "value": "A lightweight /health endpoint returns the current Unix timestamp and can be used by load balancers and orchestrators for liveness and readiness checks."
    },
    {
      "op": "add",
      "path": "/integration/observability/-",
      "value": "Prometheus metrics are exposed via prometheus-fastapi-instrumentator on the /metrics endpoint, enabling collection of HTTP request metrics and custom instrumentation."
    },
    {
      "op": "add",
      "path": "/integration/observability/-",
      "value": "Structured logging is provided via the infinity_emb.log_handler logger, optionally using rich's RichHandler for human‑readable console logs with log levels configurable via INFINITY_LOG_LEVEL."
    },
    {
      "op": "add",
      "path": "/integration/observability/-",
      "value": "An anonymized telemetry client based on PostHog captures startup events and basic environment information (e.g., hardware, cloud provider, capabilities) unless disabled via DO_NOT_TRACK or INFINITY_ANONYMOUS_USAGE_STATS."
    },
    {
      "op": "add",
      "path": "/governance/policies/-",
      "value": "Infinity is distributed under the MIT License, and all contributions must be compatible with this license."
    },
    {
      "op": "add",
      "path": "/governance/policies/-",
      "value": "The project collects anonymized usage telemetry via PostHog by default, but this can be disabled by setting environment variables such as DO_NOT_TRACK=1 or INFINITY_ANONYMOUS_USAGE_STATS=0."
    },
    {
      "op": "add",
      "path": "/governance/policies/-",
      "value": "Pull requests are expected to follow the documented contribution guidelines, pass the precommit and CI test suites, and respect the open‑source licensing of upstream models loaded from Hugging Face."
    },
    {
      "op": "add",
      "path": "/provenance/changelog/-",
      "value": {
        "date": "2026-02-27T00:11:32.311Z",
        "summary": "ML System Card run run-2026-02-27-00-11-08 observed 242 changed files",
        "files": [
          {
            "path": ".github/ISSUE_TEMPLATE/bug-report.yml"
          },
          {
            "path": ".github/ISSUE_TEMPLATE/config.yml"
          },
          {
            "path": ".github/ISSUE_TEMPLATE/feature-request.yml"
          },
          {
            "path": ".github/ISSUE_TEMPLATE/new-model-addition.yml"
          },
          {
            "path": ".github/actions/disk_cleanup/action.yml"
          },
          {
            "path": ".github/actions/poetry_setup/action.yml"
          },
          {
            "path": ".github/pull_request_template.md"
          },
          {
            "path": ".github/tools/git-restore-mtime"
          },
          {
            "path": ".github/workflows/ci.yaml"
          },
          {
            "path": ".github/workflows/docs.yaml"
          },
          {
            "path": ".github/workflows/generate_client.yaml"
          },
          {
            "path": ".github/workflows/linting.yaml"
          },
          {
            "path": ".github/workflows/pypi_release.yaml"
          },
          {
            "path": ".github/workflows/release.yaml"
          },
          {
            "path": ".github/workflows/release_docker_container.yaml"
          },
          {
            "path": ".github/workflows/release_modal_com.yaml"
          },
          {
            "path": ".github/workflows/test.yaml"
          },
          {
            "path": ".gitignore"
          },
          {
            "path": ".gitmodules"
          },
          {
            "path": ".tool-versions"
          },
          {
            "path": "CITATION.cff"
          },
          {
            "path": "LICENSE"
          },
          {
            "path": "README.md"
          },
          {
            "path": "docs/assets/cats_coco_sample.jpg"
          },
          {
            "path": "docs/assets/create_cli_v2_docs.sh"
          },
          {
            "path": "docs/assets/create_openapi_with_server_hook.sh"
          },
          {
            "path": "docs/assets/multilingual_calibration.utf8"
          },
          {
            "path": "docs/assets/openapi.json"
          },
          {
            "path": "docs/benchmarks/benchmarking.md"
          },
          {
            "path": "docs/benchmarks/simple_app.py"
          },
          {
            "path": "docs/demo_v0_0_1.gif"
          },
          {
            "path": "docs/docs/benchmarking.md"
          },
          {
            "path": "docs/docs/cli_v2.md"
          },
          {
            "path": "docs/docs/client_infinity.md"
          },
          {
            "path": "docs/docs/contribution.md"
          },
          {
            "path": "docs/docs/deploy.md"
          },
          {
            "path": "docs/docs/embed.md"
          },
          {
            "path": "docs/docs/index.md"
          },
          {
            "path": "docs/docs/integrations.md"
          },
          {
            "path": "docs/docs/python_engine.md"
          },
          {
            "path": "docs/docs/swagger_ui.md"
          },
          {
            "path": "docs/docs/telemetry.md"
          },
          {
            "path": "docs/lm_head_to_classifier/convert_lm.py"
          },
          {
            "path": "docs/mkdocs.yml"
          },
          {
            "path": "docs/ml_system_card.yaml"
          },
          {
            "path": "docs/stakeholders.yaml"
          },
          {
            "path": "infra/README.md"
          },
          {
            "path": "infra/aws_neuron/.dockerignore"
          },
          {
            "path": "infra/aws_neuron/Dockerfile.neuron"
          },
          {
            "path": "infra/aws_neuron/README.md"
          },
          {
            "path": "infra/aws_neuron/requirements_no_gpu.txt"
          },
          {
            "path": "infra/baseten/README.md"
          },
          {
            "path": "infra/dstack/README.md"
          },
          {
            "path": "infra/kubeai_k8s/README.md"
          },
          {
            "path": "infra/modal/README.md"
          },
          {
            "path": "infra/modal/functional.py"
          },
          {
            "path": "infra/modal/webserver.py"
          },
          {
            "path": "infra/runpod"
          },
          {
            "path": "infra/sap/README.md"
          },
          {
            "path": "infra/sap/sap-core-ai"
          },
          {
            "path": "infra/skypilot/README.md"
          },
          {
            "path": "infra/skypilot/skypilot-infinity.yaml"
          },
          {
            "path": "infra/vast/README.md"
          },
          {
            "path": "infra/vast/vast_instance_view.png"
          },
          {
            "path": "libs/client_infinity/Makefile"
          },
          {
            "path": "libs/client_infinity/client_config.yaml"
          },
          {
            "path": "libs/client_infinity/infinity_client/.gitignore"
          },
          {
            "path": "libs/client_infinity/infinity_client/README.md"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/__init__.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/__init__.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/__init__.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/classify.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/embeddings.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/embeddings_audio.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/embeddings_image.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/health.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/metrics_metrics_get.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/models.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/redirect_get.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/rerank.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/client.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/errors.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/__init__.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/audio_embedding_input.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/classify_input.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/classify_object.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/classify_result.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/classify_result_object.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/embedding_encoding_format.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/embedding_object.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/embedding_object_object.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/http_validation_error.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/image_embedding_input.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/model_info.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/model_info_object.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/model_info_owned_by.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_audio.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_audio_modality.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_image.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_image_modality.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_text.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_text_modality.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_result.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_result_object.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/open_ai_model_info.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/re_rank_object.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/re_rank_result.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/re_rank_result_object.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/rerank_input.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/response_health.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/stats.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/usage.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/validation_error.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/py.typed"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/types.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/vision_client.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/poetry.lock"
          },
          {
            "path": "libs/client_infinity/infinity_client/pyproject.toml"
          },
          {
            "path": "libs/client_infinity/run_generate_with_hook.sh"
          },
          {
            "path": "libs/client_infinity/run_tests_with_hook.sh"
          },
          {
            "path": "libs/client_infinity/template/README.md.jinja"
          },
          {
            "path": "libs/client_infinity/template/pypproject.toml.jinja"
          },
          {
            "path": "libs/client_infinity/template/vision_client.py"
          },
          {
            "path": "libs/client_infinity/tests/conftest.py"
          },
          {
            "path": "libs/client_infinity/tests/test_client.py"
          },
          {
            "path": "libs/embed_package/Makefile"
          },
          {
            "path": "libs/embed_package/README.md"
          },
          {
            "path": "libs/embed_package/embed/__init__.py"
          },
          {
            "path": "libs/embed_package/embed/_infer.py"
          },
          {
            "path": "libs/embed_package/embed/py.typed"
          },
          {
            "path": "libs/embed_package/poetry.lock"
          },
          {
            "path": "libs/embed_package/pyproject.toml"
          },
          {
            "path": "libs/embed_package/tests/__init__.py"
          },
          {
            "path": "libs/infinity_emb/.dockerignore"
          },
          {
            "path": "libs/infinity_emb/Docker.template.yaml"
          },
          {
            "path": "libs/infinity_emb/Dockerfile.amd_auto"
          },
          {
            "path": "libs/infinity_emb/Dockerfile.cpu_auto"
          },
          {
            "path": "libs/infinity_emb/Dockerfile.jinja2"
          },
          {
            "path": "libs/infinity_emb/Dockerfile.nvidia_auto"
          },
          {
            "path": "libs/infinity_emb/Dockerfile.trt_onnx_auto"
          },
          {
            "path": "libs/infinity_emb/Makefile"
          },
          {
            "path": "libs/infinity_emb/README.md"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/_optional_imports.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/args.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/cli.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/engine.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/env.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/fastapi_schemas/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/fastapi_schemas/data_uri.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/fastapi_schemas/docs.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/fastapi_schemas/errors.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/fastapi_schemas/pydantic_v2.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/fastapi_schemas/pymodels.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/inference/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/inference/batch_handler.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/inference/caching_layer.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/inference/loading_strategy.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/inference/queue.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/inference/select_model.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/inference/threading_asyncio.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/infinity_server.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/log_handler.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/primitives.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/py.typed"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/sync_engine.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/telemetry.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/abstract.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/acceleration.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/audio/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/audio/torch.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/audio/utils.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/classifier/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/classifier/optimum.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/classifier/torch.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/crossencoder/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/crossencoder/optimum.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/crossencoder/torch.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/embedder/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/embedder/ct2.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/embedder/dummytransformer.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/embedder/neuron.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/embedder/optimum.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/embedder/sentence_transformer.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/quantization/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/quantization/interface.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/quantization/quant.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/utils.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/utils_optimum.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/vision/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/vision/torch_vision.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/vision/utils.py"
          },
          {
            "path": "libs/infinity_emb/poetry.lock"
          },
          {
            "path": "libs/infinity_emb/poetry.toml"
          },
          {
            "path": "libs/infinity_emb/pyproject.toml"
          },
          {
            "path": "libs/infinity_emb/requirements_install_from_poetry.sh"
          },
          {
            "path": "libs/infinity_emb/tests/__init__.py"
          },
          {
            "path": "libs/infinity_emb/tests/conftest.py"
          },
          {
            "path": "libs/infinity_emb/tests/data/audio/beep.wav"
          },
          {
            "path": "libs/infinity_emb/tests/data/audio/cat_meow.wav"
          },
          {
            "path": "libs/infinity_emb/tests/data/benchmark/benchmark_embed.json"
          },
          {
            "path": "libs/infinity_emb/tests/data/benchmark/benchmark_embed_image.json"
          },
          {
            "path": "libs/infinity_emb/tests/data/datasets/stsbenchmark.tsv.gz"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/__init__.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/conftest.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_api_with_dummymodel.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_authentication.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_ct2_sentence.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_openapi_client_compat.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_optimum_embedding.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_sentence_transformers.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_sentence_transformers_colbert.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_torch_audio.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_torch_classify.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_torch_reranker.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_torch_vision.py"
          },
          {
            "path": "libs/infinity_emb/tests/install_test.sh"
          },
          {
            "path": "libs/infinity_emb/tests/script_live.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/fastapi_schemas/test_data_uri.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/fastapi_schemas/test_errors.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/fastapi_schemas/test_response.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/inference/test_batch_handler.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/inference/test_caching_layer.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/inference/test_models.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/inference/test_select_model.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/test_args.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/test_cli.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/test_engine.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/test_infinity_server.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/test_log_handler.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/test_sync_engine.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/audio/test_audio.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/classifier/test_optimum_classifier.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/classifier/test_torch_classifer.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/crossencoder/test_optimum_crossencoder.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/crossencoder/test_torch_crossencoder.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/embedder/test_optimum.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/embedder/test_torch.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/quantization/test_interface.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/test_utils.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/vision/test_torch_vision.py"
          }
        ],
        "runId": "run-2026-02-27-00-11-08",
        "headSha": "edd6b36655ccf807c263676a48d184656be1069d"
      }
    }
  ],
  "card_patch": [
    {
      "op": "add",
      "path": "/stakeholderNotes",
      "value": {
        "data-engineer": {
          "textMd": "",
          "overview": "The embedding service is a Python-based HTTP system (see $.devInsight.codeOverview.languages) exposing embedding, rerank, and classification capabilities via FastAPI endpoints ⚠️ (see $.devInsight.architecture.publicApis). Clients interact primarily through HTTP routes and a CLI entrypoint (see $.devInsight.codeOverview.entrypoints). Internally, a core server/engine component manages model loading, batching, and inference ⚠️ (see $.devInsight.codeOverview.components). Data likely flows from client requests through FastAPI routing into model-specific transformers before responses are serialized and returned ⚠️ (see $.devInsight.architecture.dataFlow). FastAPI/Uvicorn and ML/transformer libraries form the main dependency surface ⚠️ (see $.devInsight.architecture.depsSummary).",
          "changes": "- No significant updates detected.\n- Behavior, data flow, and public APIs described in $.devInsight.architecture.dataFlow ⚠️ and $.devInsight.architecture.publicApis ⚠️ appear consistent with the existing Infinity embedding server.\n- Core components and entrypoints in $.devInsight.codeOverview.components ⚠️ and $.devInsight.codeOverview.entrypoints remain the authoritative references for how data engineers should integrate and operate the service.",
          "confidence": 0.2
        },
        "data-scientist": {
          "textMd": "",
          "overview": "Infinity⚠️ is described in $.business.executiveSummary as an open-source, high-throughput, low-latency REST API server for embedding and reranking workloads⚠️. For data scientists, the card positions it as infrastructure that exposes multiple models behind a unified API, simplifying experimentation and deployment across text, image, and potentially audio embeddings⚠️. The intended use in $.business.intendedUse emphasizes serving models reliably in production-like environments⚠️, enabling you to focus on model selection, evaluation, and integration rather than bespoke serving stacks⚠️.",
          "changes": "- $.business.executiveSummary: Wording updated⚠️ to stress Infinity’s role as a generic, open-source REST API server for embeddings and reranking, clarifying performance characteristics (throughput/latency)⚠️.\n- $.business.intendedUse: Clarifies that the primary consumers are developers and infrastructure teams⚠️, with implications for how data scientists integrate via APIs.\n- $.business.useCase: Refines examples of deploying and serving multiple embedding and reranking models under one service⚠️.\n- $.business.userPopulations: Explicitly lists \"Data Scientist\" among target users⚠️, alongside ML Engineer, Product Manager, and governance-focused roles⚠️.",
          "confidence": 0.2
        },
        "domain-expert": {
          "textMd": "",
          "overview": "According to $.business.executiveSummary⚠️, Infinity is an open‑source, high‑throughput, low‑latency REST API server for deploying and serving embedding and reranking models. As described in $.business.intendedUse⚠️, it is aimed at developers and infrastructure teams who need scalable model serving infrastructure. Per $.business.useCase⚠️, it supports multiple embedding and reranking models behind a unified interface. The listed user populations in $.business.userPopulations⚠️ include Data Scientists, ML Engineers, Product Managers, and Governance / Compliance stakeholders.",
          "changes": "- No significant updates detected in the referenced ML System Card sections ($.business.executiveSummary⚠️, $.business.intendedUse⚠️, $.business.useCase⚠️, $.business.userPopulations⚠️) compared with the baseline for this run.\n- Any minor wording or formatting adjustments, if present, do not materially change the described purpose, usage patterns, or primary user groups of the Infinity system.",
          "confidence": 0.2
        },
        "governance-compliance-ethics-officer": {
          "textMd": "",
          "overview": "The ML System Card’s governance section focuses on licensing and contributor obligations associated with the Infinity project. Under $.governance.policies, the card appears to describe that Infinity is distributed under the MIT License and that contributions must follow defined project rules and standards ⚠️. This section is intended to inform governance, compliance, and ethics stakeholders about the open-source licensing basis, the framework for acceptable contributions, and how these elements support responsible maintenance and oversight of the system over time.",
          "changes": "- No significant updates detected in $.governance.policies between the base and head revisions.\n- No newly documented governance, compliance, or ethics controls were identified in this run.\n- Existing descriptions related to licensing and contributor obligations under $.governance.policies appear unchanged ⚠️.",
          "confidence": 0.2
        },
        "governance-officer": {
          "textMd": "",
          "overview": "The ML System Card’s governance section documents high‑level policies governing how the Infinity system is distributed and contributed to. It specifies licensing terms and contribution requirements ⚠️, which are relevant for legal compliance, IP management, and ensuring that Data Scientists understand permissible use and modification of the system. Governance officers can use the policies in `$.governance.policies` as the primary reference for aligning internal procedures (e.g., review, approval, and auditing) with the project’s stated legal and contribution framework.",
          "changes": "- No significant updates detected in `$.governance.policies` based on the available comparison metadata.\n- Any detailed modifications to policy wording, contributor obligations, or licensing references ⚠️ are not fully resolvable from the provided run information and should be confirmed by directly reviewing `docs/ml_system_card.yaml` at `$.governance.policies`.\n- Recommend a manual check to verify whether any new restrictions, obligations, or clarifications have been added that could impact Data Scientist workflows or compliance processes.",
          "confidence": 0.2
        },
        "ml-engineer": {
          "textMd": "",
          "overview": "This repository provides a Python-based embedding and reranking service, with a core engine under $.devInsight.codeOverview.components ⚠️. The service exposes HTTP endpoints for embeddings, reranking, classification, and health checks as summarized in $.devInsight.architecture.publicApis ⚠️. Inference and serving are orchestrated via a CLI entrypoint (\"infinity_emb\" with a \"v2\" subcommand) noted in $.devInsight.codeOverview.entrypoints. The stack is primarily Python per $.devInsight.codeOverview.languages, with an HTTP server and routing layer inferred in $.devInsight.architecture.depsSummary ⚠️. Request handling and data flow are outlined at a high level in $.devInsight.architecture.dataFlow ⚠️.",
          "changes": "- No significant updates detected.",
          "confidence": 0.2
        },
        "product-manager": {
          "textMd": "",
          "overview": "Infinity ⚠️ (from $.business.executiveSummary) is described as an open‑source, high‑throughput, low‑latency REST API server for ML embeddings and reranking. Its intended role ⚠️ (from $.business.intendedUse) is to let developers and infrastructure teams deploy and manage multiple embedding and reranking models behind a unified API, optimizing performance and scalability. Typical use cases ⚠️ (from $.business.useCase) include powering semantic search, recommendations, and retrieval‑augmented applications, primarily for technical and product stakeholders ⚠️ (from $.business.userPopulations) such as Data Scientists, ML Engineers, Product Managers, and governance teams.",
          "changes": "- No significant updates detected in the referenced ML System Card sections:\n  - $.business.executiveSummary ⚠️\n  - $.business.intendedUse ⚠️\n  - $.business.useCase ⚠️\n  - $.business.userPopulations ⚠️",
          "confidence": 0.2
        },
        "project-manager": {
          "textMd": "",
          "overview": "According to $.business.executiveSummary ⚠️, Infinity is an open‑source, high‑throughput, low‑latency REST API server for embedding and reranking models. As described in $.business.intendedUse ⚠️, it is intended for developers and infrastructure teams to deploy and operate multiple models behind a unified API. Per $.business.useCase ⚠️, typical uses include serving text, image, audio embeddings and reranking for search, recommendation, and similar workloads. $.business.userPopulations ⚠️ lists core users as Data Scientists, ML Engineers, Product Managers, and Governance/Compliance stakeholders.",
          "changes": "- No significant updates detected to the business‑level description fields in the ML System Card (see $.business.*).",
          "confidence": 0.2
        },
        "software-developer": {
          "textMd": "",
          "overview": "According to $.business.executiveSummary ⚠️, Infinity is an open‑source, high‑throughput, low‑latency REST API server for deploying and serving embedding and reranking models at scale. Per $.business.intendedUse ⚠️, it is meant to give developers and infrastructure teams a unified service to host multiple models behind a consistent API, simplifying integration into applications and pipelines. As described in $.business.useCase ⚠️, typical usage focuses on search, retrieval‑augmented generation, recommendation, and classification workloads for production environments.",
          "changes": "- No significant updates detected to the ML System Card fields referenced for this stakeholder.\n- Current understanding of target users remains: [\"Data Scientist\", \"ML Engineer\", \"Product Manager\", \"Governance, Compliance & E...\"] per $.business.userPopulations ⚠️.\n- Business framing of the system’s purpose and usage patterns in $.business.executiveSummary, $.business.intendedUse, and $.business.useCase ⚠️ appears unchanged in this run.",
          "confidence": 0.2
        },
        "ux-researcher": {
          "textMd": "",
          "overview": "Infinity is described as an open‑source, high‑throughput, low‑latency REST API server for ML embeddings and reranking (⚠️ $.business.executiveSummary). It is intended to be used by developers and infrastructure teams to deploy and manage multiple embedding and reranking models behind a unified service (⚠️ $.business.intendedUse, $.business.useCase). Primary user populations currently listed include Data Scientists, ML Engineers, Product Managers, and Governance/Compliance stakeholders (⚠️ $.business.userPopulations). UX implications: multi‑role workflows and observability across performance, latency, and reliability.",
          "changes": "- No significant updates detected in the ML System Card fields relevant to UX research.\n- Current descriptions of system purpose and capabilities remain as in: `$.business.executiveSummary`, `$.business.intendedUse`, `$.business.useCase` (⚠️).\n- Listed user populations are unchanged in `$.business.userPopulations` (⚠️).\n- For UX planning, assume the same multi‑stakeholder audience and core tasks (model deployment, monitoring, and usage) as in the prior version of the card.",
          "confidence": 0.2
        }
      }
    },
    {
      "op": "add",
      "path": "/meta/maturity",
      "value": "Production"
    },
    {
      "op": "replace",
      "path": "/meta/title",
      "value": "ML System Card (GitHub-native, PR-first)"
    },
    {
      "op": "add",
      "path": "/meta/owners/-",
      "value": {
        "name": "Michael Feil",
        "role": "maintainer"
      }
    },
    {
      "op": "add",
      "path": "/meta/owners/-",
      "value": {
        "name": "Raphael Wirth",
        "role": "maintainer"
      }
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "embeddings"
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "reranking"
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "multimodal"
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "REST-API"
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "HuggingFace"
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "FastAPI"
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "OpenAI-compatible"
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "CTranslate2"
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "ONNXRuntime"
    },
    {
      "op": "add",
      "path": "/meta/tags/-",
      "value": "PyTorch"
    },
    {
      "op": "add",
      "path": "/meta/links/repo",
      "value": "https://github.com/michaelfeil/infinity"
    },
    {
      "op": "add",
      "path": "/meta/links/demo",
      "value": "https://infinity.modal.michaelfeil.eu"
    },
    {
      "op": "add",
      "path": "/meta/links/dataset",
      "value": "https://raw.githubusercontent.com/michaelfeil/infinity/2da1f32d610b8edbe4ce58d0c44fc27c963abca6/docs/assets/multilingual_calibration.utf8"
    },
    {
      "op": "add",
      "path": "/business/executiveSummary",
      "value": "Infinity is an open‑source, high‑throughput, low‑latency REST API server for serving text, image, and audio embeddings, reranking models, and related classification tasks. It wraps a wide range of Hugging Face models and backends (PyTorch, Optimum/ONNX Runtime, CTranslate2, AWS Neuron) behind an OpenAI‑compatible embeddings API and a Cohere‑style rerank API. The system focuses on production‑grade serving features such as dynamic batching, support for multiple accelerators (NVIDIA CUDA, AMD ROCm, CPU, AWS INF2, Apple MPS), and multimodal capabilities including CLIP, CLAP, ColBERT, and ColPali. Infinity exposes both a FastAPI‑based HTTP server and Python/HTTP clients, and is extensively unit‑ and end‑to‑end‑tested to ensure that outputs closely match reference implementations from sentence‑transformers and other upstream models. It is distributed under the MIT License and is already integrated with several deployment and orchestration platforms such as Modal, Runpod, Vast.ai, KubeAI, and Baseten."
    },
    {
      "op": "add",
      "path": "/business/intendedUse",
      "value": "The intended use of Infinity is to provide developers and infrastructure teams with a self‑hosted, production‑ready service for embedding, reranking, and related classification models, exposing them over stable HTTP APIs or a Python interface. Typical downstream applications include retrieval‑augmented generation (RAG), semantic search, recommendation systems, clustering, and multimodal search over text, images, and audio. Infinity is designed to be dropped into existing stacks that expect OpenAI‑style embeddings or Cohere‑style rerank APIs, or to be orchestrated as a microservice via platforms like Kubernetes, Modal, Runpod, or Vast.ai. It is not intended to train models from scratch, but rather to host and optimize inference for pretrained models fetched from Hugging Face or local directories."
    },
    {
      "op": "add",
      "path": "/business/useCase",
      "value": "Infinity is used to deploy and serve multiple embedding and reranking models as a single high‑performance service, allowing applications to compute semantic vector representations for text, images, and audio, rerank document lists given queries, and run multi‑label text classification. It targets scenarios where teams want to self‑host or control their own embedding stack while keeping compatibility with popular APIs like OpenAI embeddings and Cohere rerank, for example to reduce latency, control data residency, or switch between different Hugging Face models. Common use cases include powering search indices and vector databases, document and code retrieval for LLMs, semantic similarity and clustering pipelines, and multimodal search such as image‑by‑text or audio‑by‑text retrieval."
    },
    {
      "op": "add",
      "path": "/business/userPopulations/-",
      "value": "Data Scientist"
    },
    {
      "op": "add",
      "path": "/business/userPopulations/-",
      "value": "ML Engineer"
    },
    {
      "op": "add",
      "path": "/business/userPopulations/-",
      "value": "Product Manager"
    },
    {
      "op": "add",
      "path": "/business/userPopulations/-",
      "value": "Governance, Compliance & Ethics Officer"
    },
    {
      "op": "add",
      "path": "/business/userPopulations/-",
      "value": "Data Engineer"
    },
    {
      "op": "add",
      "path": "/business/userPopulations/-",
      "value": "Software Developer"
    },
    {
      "op": "add",
      "path": "/business/userPopulations/-",
      "value": "UX Researcher"
    },
    {
      "op": "add",
      "path": "/business/userPopulations/-",
      "value": "Project Manager"
    },
    {
      "op": "add",
      "path": "/business/userPopulations/-",
      "value": "Domain Expert"
    },
    {
      "op": "add",
      "path": "/devInsight/codeOverview/languages/-",
      "value": "Python"
    },
    {
      "op": "add",
      "path": "/devInsight/codeOverview/entrypoints/-",
      "value": "CLI entrypoint 'infinity_emb' with subcommand 'v2' for launching one or more models as an HTTP server (defined in libs/infinity_emb/infinity_emb/cli.py)."
    },
    {
      "op": "add",
      "path": "/devInsight/codeOverview/entrypoints/-",
      "value": "Python API entrypoints AsyncEmbeddingEngine and AsyncEngineArray for direct async inference over text, image, and audio (libs/infinity_emb/infinity_emb/engine.py)."
    },
    {
      "op": "add",
      "path": "/devInsight/codeOverview/entrypoints/-",
      "value": "SyncEngineArray and embed.BatchedInference for synchronous, batched embedding and reranking from Python code (libs/infinity_emb/infinity_emb/sync_engine.py, libs/embed_package/embed/_infer.py)."
    },
    {
      "op": "add",
      "path": "/devInsight/codeOverview/entrypoints/-",
      "value": "FastAPI application factory create_server for embedding, rerank, classify, and health/metrics endpoints (libs/infinity_emb/infinity_emb/infinity_server.py)."
    },
    {
      "op": "add",
      "path": "/devInsight/codeOverview/entrypoints/-",
      "value": "Generated HTTP clients Client and AuthenticatedClient in the infinity_client package for remote access to an Infinity deployment (libs/client_infinity/infinity_client/infinity_client/client.py)."
    },
    {
      "op": "add",
      "path": "/devInsight/codeOverview/components/-",
      "value": {
        "name": "Infinity core server and engine",
        "summary": "Implements the CLI, FastAPI server creation, async and sync embedding engines, batching, model selection, and transformer backends for text, image, audio, reranking, and classification.",
        "keyFiles": [
          "libs/infinity_emb/infinity_emb/cli.py",
          "libs/infinity_emb/infinity_emb/infinity_server.py",
          "libs/infinity_emb/infinity_emb/engine.py",
          "libs/infinity_emb/infinity_emb/inference/batch_handler.py",
          "libs/infinity_emb/infinity_emb/inference/select_model.py",
          "libs/infinity_emb/infinity_emb/transformer/"
        ]
      }
    },
    {
      "op": "add",
      "path": "/devInsight/codeOverview/components/-",
      "value": {
        "name": "Infinity REST API client",
        "summary": "A generated HTTP client library (sync and async) that wraps Infinity's OpenAPI specification, providing typed methods for /embeddings, /rerank, /classify, /models, /health, and /metrics.",
        "keyFiles": [
          "libs/client_infinity/infinity_client/README.md",
          "libs/client_infinity/infinity_client/infinity_client/client.py",
          "libs/client_infinity/infinity_client/infinity_client/api/default/"
        ]
      }
    },
    {
      "op": "add",
      "path": "/devInsight/codeOverview/components/-",
      "value": {
        "name": "Embed convenience library",
        "summary": "A high‑level sync‑to‑async wrapper (embed package) that uses SyncEngineArray and EngineArgs to batch and schedule inference calls across one or more models, exposing simple embed, rerank, classify, image_embed, and audio_embed methods returning futures.",
        "keyFiles": [
          "libs/embed_package/README.md",
          "libs/embed_package/embed/_infer.py",
          "libs/embed_package/pyproject.toml"
        ]
      }
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/publicApis/-",
      "value": {
        "name": "Health check",
        "path": "/health",
        "file": "libs/infinity_emb/infinity_emb/infinity_server.py"
      }
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/publicApis/-",
      "value": {
        "name": "List models",
        "path": "/models",
        "file": "libs/infinity_emb/infinity_emb/infinity_server.py"
      }
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/publicApis/-",
      "value": {
        "name": "Embeddings (multimodal, OpenAI‑compatible)",
        "path": "/embeddings",
        "file": "libs/infinity_emb/infinity_emb/infinity_server.py"
      }
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/publicApis/-",
      "value": {
        "name": "Rerank (Cohere‑style)",
        "path": "/rerank",
        "file": "libs/infinity_emb/infinity_emb/infinity_server.py"
      }
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/publicApis/-",
      "value": {
        "name": "Classify (text classification)",
        "path": "/classify",
        "file": "libs/infinity_emb/infinity_emb/infinity_server.py"
      }
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/publicApis/-",
      "value": {
        "name": "Image embeddings (legacy)",
        "path": "/embeddings_image",
        "file": "libs/infinity_emb/infinity_emb/infinity_server.py"
      }
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/publicApis/-",
      "value": {
        "name": "Audio embeddings (legacy)",
        "path": "/embeddings_audio",
        "file": "libs/infinity_emb/infinity_emb/infinity_server.py"
      }
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/publicApis/-",
      "value": {
        "name": "Prometheus metrics",
        "path": "/metrics",
        "file": "libs/infinity_emb/infinity_emb/infinity_server.py"
      }
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/dataFlow/-",
      "value": "Client sends HTTP requests (e.g., POST /embeddings, /rerank, /classify) to the FastAPI application created by infinity_emb.infinity_server.create_server, optionally including a Bearer API key when authentication is enabled."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/dataFlow/-",
      "value": "The FastAPI route handler (e.g., _embeddings, _rerank, _classify) validates and parses the request body into Pydantic models (MultiModalOpenAIEmbedding, RerankInput, ClassifyInput), including modality routing for text, image, or audio inputs and optional matryoshka dimension truncation."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/dataFlow/-",
      "value": "The handler resolves the target model by name via _resolve_engine, which selects an AsyncEmbeddingEngine instance from an AsyncEngineArray; if the engine's internal BatchHandler queue is overloaded, it raises a 429 OpenAI‑style error before queuing more work."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/dataFlow/-",
      "value": "AsyncEmbeddingEngine delegates work to BatchHandler, which places inputs into a prioritized queue (CustomFIFOQueue) where priorities are computed from token lengths (get_lengths_with_tokenize, optionally using model‑specific tokenizers) to build dynamically sized batches up to a configured max_batch_size and queue_size."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/dataFlow/-",
      "value": "ModelWorker threads perform a three‑stage pipeline around each batch: encode_pre (tokenization / feature extraction and device transfer), encode_core (forward pass via backend‑specific encoder such as SentenceTransformerPatched, OptimumEmbedder, CrossEncoder, TIMM, or TorchAudioModel), and encode_post (pooling, normalization, and optional post‑forward quantization via quant_embedding_decorator)."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/dataFlow/-",
      "value": "For image and audio modalities, helper functions resolve_images and resolve_audios download URLs with aiohttp, decode base64 data URIs, validate size or sampling rate, and wrap them as ImageSingle or AudioSingle objects before scheduling through the same batching pipeline."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/dataFlow/-",
      "value": "BatchHandler collects results from model workers, optionally applies matryoshka_dim slicing of embeddings, and returns embeddings, scores, or classification outputs plus token usage counts to AsyncEmbeddingEngine, which passes them back to the FastAPI route."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/dataFlow/-",
      "value": "Route handlers format outputs into OpenAI‑style or Cohere‑style JSON envelopes (OpenAIEmbeddingResult, ReRankResult, ClassifyResult), add usage metadata, and send them over HTTP; in parallel, optional diskcache caching and anonymous PostHog telemetry may run asynchronously in the background."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/depsSummary/-",
      "value": "FastAPI and Uvicorn provide the HTTP server, routing, and OpenAPI documentation for Infinity's REST API."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/depsSummary/-",
      "value": "Hugging Face Transformers, sentence-transformers, and huggingface_hub are used to load and run text, image, and audio models from the Hugging Face Hub or local directories."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/depsSummary/-",
      "value": "PyTorch is the primary deep learning backend for 'torch' engine models, with optional acceleration via BetterTransformer and torch.compile."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/depsSummary/-",
      "value": "Optimum and onnxruntime (including CUDA, TensorRT, ROCm, and OpenVINO providers) are used for optimized ONNX‑based inference when the 'optimum' engine is selected."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/depsSummary/-",
      "value": "CTranslate2 provides an alternative quantized CPU/GPU backend for some BERT‑style embedding models when the 'ctranslate2' engine is chosen."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/depsSummary/-",
      "value": "colpali-engine and timm are used for visual and ColPali/ColQwen2‑style late‑interaction image–text models; soundfile and related libraries are used for CLAP‑style audio models."
    },
    {
      "op": "add",
      "path": "/devInsight/architecture/depsSummary/-",
      "value": "diskcache optionally stores embedding results on disk to reduce latency on repeated queries; prometheus-fastapi-instrumentator exposes Prometheus /metrics; posthog is used for anonymized telemetry; rich provides structured logging."
    },
    {
      "op": "add",
      "path": "/mlCore/artifactURIs",
      "value": {
        "model": "Model artifacts are referenced by Hugging Face model IDs or local directories configured at runtime, for example 'BAAI/bge-small-en-v1.5', 'mixedbread-ai/mxbai-rerank-xsmall-v1', or 'wkcn/TinyCLIP-ViT-8M-16-Text-3M-YFCC15M'.",
        "dockerImage": "docker.io/michaelf34/infinity:latest"
      }
    },
    {
      "op": "add",
      "path": "/mlCore/training",
      "value": {
        "framework": "PyTorch, Hugging Face Transformers, sentence-transformers, Optimum/ONNX Runtime, CTranslate2",
        "frameworkVersion": "Versions are controlled by the infinity_emb package dependencies (e.g., torch>=2.2.1, transformers>=4.47.0, optimum>=1.24.0, sentence-transformers^3.0.1).",
        "hyperparams": {},
        "hardware": "Designed for inference on CPU, NVIDIA CUDA GPUs, AMD ROCm GPUs, AWS Neuron (INF2), and Apple MPS accelerators; no model training is performed within this repository."
      }
    },
    {
      "op": "replace",
      "path": "/mlCore/problem",
      "value": "Infinity serves pretrained models for semantic representation learning and retrieval tasks, including text, image, and audio embeddings, late‑interaction ColBERT/ColPali embeddings, query–document reranking, and multi‑label text classification, in an inference‑only setting."
    },
    {
      "op": "add",
      "path": "/mlCore/datasets/-",
      "value": {
        "name": "multilingual_calibration.utf8",
        "uri": "https://raw.githubusercontent.com/michaelfeil/infinity/2da1f32d610b8edbe4ce58d0c44fc27c963abca6/docs/assets/multilingual_calibration.utf8",
        "license": "Not specified"
      }
    },
    {
      "op": "add",
      "path": "/mlCore/qualities/-",
      "value": "Infinity's embedding outputs for supported models are validated against reference implementations (e.g., sentence-transformers and fastembed) in unit and end‑to‑end tests, checking for high cosine similarity and small numeric tolerances."
    },
    {
      "op": "add",
      "path": "/mlCore/qualities/-",
      "value": "Dynamic batching and async request handling are used to achieve high throughput and low latency, with performance tests comparing BatchHandler throughput to baseline sentence-transformers encoding."
    },
    {
      "op": "add",
      "path": "/mlCore/qualities/-",
      "value": "Support for multiple optimized backends (PyTorch with BetterTransformer and torch.compile, Optimum/ONNX Runtime, CTranslate2, AWS Neuron) allows deployment on diverse hardware while maintaining numerical fidelity within configured tolerances."
    },
    {
      "op": "add",
      "path": "/mlCore/qualities/-",
      "value": "Extensive automated tests cover text, image, and audio embeddings, reranking, classification, matryoshka truncation, quantized embeddings, and error handling for malformed inputs."
    },
    {
      "op": "add",
      "path": "/mlCore/failureModes/-",
      "value": "Requests that reference unsupported capabilities for a given model (e.g., calling /rerank on a pure embedding model or /classify on a reranker) raise ModelNotDeployedError and are returned as HTTP 400 errors with an OpenAI‑style error JSON."
    },
    {
      "op": "add",
      "path": "/mlCore/failureModes/-",
      "value": "If an image is too small (e.g., 1×1), corrupted, or cannot be downloaded, resolve_images raises ImageCorruption, and the /embeddings or /embeddings_image route returns HTTP 400 with a descriptive error message."
    },
    {
      "op": "add",
      "path": "/mlCore/failureModes/-",
      "value": "If an audio file cannot be downloaded, decoded, or does not match the model's required sampling rate, resolve_audios raises AudioCorruption, and the embeddings endpoint returns HTTP 400."
    },
    {
      "op": "add",
      "path": "/mlCore/failureModes/-",
      "value": "When a model's request queue exceeds the configured queue_size, AsyncEmbeddingEngine.is_overloaded() returns true and _resolve_engine rejects further requests with HTTP 429 Too Many Requests."
    },
    {
      "op": "add",
      "path": "/mlCore/failureModes/-",
      "value": "Authentication failures (missing or wrong Bearer token when INFINITY_API_KEY is set) result in HTTP 401 responses; unexpected server errors in encode or batching logic are caught and surfaced as generic HTTP 500 Internal Server Error responses."
    },
    {
      "op": "add",
      "path": "/integration/api",
      "value": {
        "inputSchema": "OpenAPI 3.0 specification defining OpenAI‑style /embeddings and Cohere‑style /rerank endpoints, plus /classify, /models, /health, and /metrics, stored in docs/assets/openapi.json.",
        "outputSchema": "JSON responses that follow OpenAI embeddings result envelopes, Cohere rerank result structures, and classification result objects, as implemented by OpenAIEmbeddingResult, ReRankResult, and ClassifyResult Pydantic models.",
        "version": "0.0.77"
      }
    },
    {
      "op": "add",
      "path": "/integration/errorModel/-",
      "value": "Invalid or unsupported model names, modalities, or capabilities (e.g., requesting rerank on a pure embedding model) raise ModelNotDeployedError and are surfaced to clients as HTTP 400 errors with an OpenAI‑style JSON error payload via OpenAIException."
    },
    {
      "op": "add",
      "path": "/integration/errorModel/-",
      "value": "Input validation failures from FastAPI/Pydantic (e.g., exceeding maximum input length, empty lists, or wrong types) result in HTTP 422 Unprocessable Entity responses with structured validation details."
    },
    {
      "op": "add",
      "path": "/integration/errorModel/-",
      "value": "When an engine's BatchHandler queue is overloaded beyond the configured queue_size, _resolve_engine triggers an HTTP 429 Too Many Requests with a descriptive message indicating the model is overloaded."
    },
    {
      "op": "add",
      "path": "/integration/errorModel/-",
      "value": "If API key authentication is enabled and the Authorization header is missing or incorrect, validate_token returns an HTTP 401 Unauthorized error with a WWW-Authenticate: Bearer header."
    },
    {
      "op": "add",
      "path": "/integration/errorModel/-",
      "value": "Unexpected internal exceptions in route handlers are caught by openai_exception_handler and returned as HTTP 500 responses with a generic 'Internal Server Error' OpenAI‑style error structure."
    },
    {
      "op": "add",
      "path": "/integration/operationalQualities/-",
      "value": "Dynamic batching in BatchHandler groups queued requests up to a configurable max_batch_size while considering token lengths, balancing latency and throughput across model replicas."
    },
    {
      "op": "add",
      "path": "/integration/operationalQualities/-",
      "value": "Queue backpressure is enforced via a bounded priority queue and the queue_size setting (INFINITY_QUEUE_SIZE), enabling calling services to detect overload conditions via 429 errors and scale horizontally."
    },
    {
      "op": "add",
      "path": "/integration/operationalQualities/-",
      "value": "Infinity can preload models at container build or startup time using the --preload-only CLI flag, which downloads and verifies model artifacts and then exits, reducing cold‑start latency in containers."
    },
    {
      "op": "add",
      "path": "/integration/operationalQualities/-",
      "value": "Configuration is environment‑variable‑driven (INFINITY_MODEL_ID, INFINITY_BATCH_SIZE, INFINITY_DEVICE, etc.), making it straightforward to run in Docker, Kubernetes, or serverless environments without modifying code."
    },
    {
      "op": "add",
      "path": "/integration/operationalQualities/-",
      "value": "Reference deployment configurations are provided for Modal, Runpod, Vast.ai, Skypilot, AWS Neuron, SAP Core AI, KubeAI, and Baseten, illustrating how to run Infinity behind various orchestrators and GPUs."
    },
    {
      "op": "add",
      "path": "/integration/observability/-",
      "value": "A lightweight /health endpoint returns the current Unix timestamp and can be used by load balancers and orchestrators for liveness and readiness checks."
    },
    {
      "op": "add",
      "path": "/integration/observability/-",
      "value": "Prometheus metrics are exposed via prometheus-fastapi-instrumentator on the /metrics endpoint, enabling collection of HTTP request metrics and custom instrumentation."
    },
    {
      "op": "add",
      "path": "/integration/observability/-",
      "value": "Structured logging is provided via the infinity_emb.log_handler logger, optionally using rich's RichHandler for human‑readable console logs with log levels configurable via INFINITY_LOG_LEVEL."
    },
    {
      "op": "add",
      "path": "/integration/observability/-",
      "value": "An anonymized telemetry client based on PostHog captures startup events and basic environment information (e.g., hardware, cloud provider, capabilities) unless disabled via DO_NOT_TRACK or INFINITY_ANONYMOUS_USAGE_STATS."
    },
    {
      "op": "add",
      "path": "/governance/policies/-",
      "value": "Infinity is distributed under the MIT License, and all contributions must be compatible with this license."
    },
    {
      "op": "add",
      "path": "/governance/policies/-",
      "value": "The project collects anonymized usage telemetry via PostHog by default, but this can be disabled by setting environment variables such as DO_NOT_TRACK=1 or INFINITY_ANONYMOUS_USAGE_STATS=0."
    },
    {
      "op": "add",
      "path": "/governance/policies/-",
      "value": "Pull requests are expected to follow the documented contribution guidelines, pass the precommit and CI test suites, and respect the open‑source licensing of upstream models loaded from Hugging Face."
    },
    {
      "op": "add",
      "path": "/provenance/changelog/-",
      "value": {
        "date": "2026-02-27T00:11:32.311Z",
        "summary": "ML System Card run run-2026-02-27-00-11-08 observed 242 changed files",
        "files": [
          {
            "path": ".github/ISSUE_TEMPLATE/bug-report.yml"
          },
          {
            "path": ".github/ISSUE_TEMPLATE/config.yml"
          },
          {
            "path": ".github/ISSUE_TEMPLATE/feature-request.yml"
          },
          {
            "path": ".github/ISSUE_TEMPLATE/new-model-addition.yml"
          },
          {
            "path": ".github/actions/disk_cleanup/action.yml"
          },
          {
            "path": ".github/actions/poetry_setup/action.yml"
          },
          {
            "path": ".github/pull_request_template.md"
          },
          {
            "path": ".github/tools/git-restore-mtime"
          },
          {
            "path": ".github/workflows/ci.yaml"
          },
          {
            "path": ".github/workflows/docs.yaml"
          },
          {
            "path": ".github/workflows/generate_client.yaml"
          },
          {
            "path": ".github/workflows/linting.yaml"
          },
          {
            "path": ".github/workflows/pypi_release.yaml"
          },
          {
            "path": ".github/workflows/release.yaml"
          },
          {
            "path": ".github/workflows/release_docker_container.yaml"
          },
          {
            "path": ".github/workflows/release_modal_com.yaml"
          },
          {
            "path": ".github/workflows/test.yaml"
          },
          {
            "path": ".gitignore"
          },
          {
            "path": ".gitmodules"
          },
          {
            "path": ".tool-versions"
          },
          {
            "path": "CITATION.cff"
          },
          {
            "path": "LICENSE"
          },
          {
            "path": "README.md"
          },
          {
            "path": "docs/assets/cats_coco_sample.jpg"
          },
          {
            "path": "docs/assets/create_cli_v2_docs.sh"
          },
          {
            "path": "docs/assets/create_openapi_with_server_hook.sh"
          },
          {
            "path": "docs/assets/multilingual_calibration.utf8"
          },
          {
            "path": "docs/assets/openapi.json"
          },
          {
            "path": "docs/benchmarks/benchmarking.md"
          },
          {
            "path": "docs/benchmarks/simple_app.py"
          },
          {
            "path": "docs/demo_v0_0_1.gif"
          },
          {
            "path": "docs/docs/benchmarking.md"
          },
          {
            "path": "docs/docs/cli_v2.md"
          },
          {
            "path": "docs/docs/client_infinity.md"
          },
          {
            "path": "docs/docs/contribution.md"
          },
          {
            "path": "docs/docs/deploy.md"
          },
          {
            "path": "docs/docs/embed.md"
          },
          {
            "path": "docs/docs/index.md"
          },
          {
            "path": "docs/docs/integrations.md"
          },
          {
            "path": "docs/docs/python_engine.md"
          },
          {
            "path": "docs/docs/swagger_ui.md"
          },
          {
            "path": "docs/docs/telemetry.md"
          },
          {
            "path": "docs/lm_head_to_classifier/convert_lm.py"
          },
          {
            "path": "docs/mkdocs.yml"
          },
          {
            "path": "docs/ml_system_card.yaml"
          },
          {
            "path": "docs/stakeholders.yaml"
          },
          {
            "path": "infra/README.md"
          },
          {
            "path": "infra/aws_neuron/.dockerignore"
          },
          {
            "path": "infra/aws_neuron/Dockerfile.neuron"
          },
          {
            "path": "infra/aws_neuron/README.md"
          },
          {
            "path": "infra/aws_neuron/requirements_no_gpu.txt"
          },
          {
            "path": "infra/baseten/README.md"
          },
          {
            "path": "infra/dstack/README.md"
          },
          {
            "path": "infra/kubeai_k8s/README.md"
          },
          {
            "path": "infra/modal/README.md"
          },
          {
            "path": "infra/modal/functional.py"
          },
          {
            "path": "infra/modal/webserver.py"
          },
          {
            "path": "infra/runpod"
          },
          {
            "path": "infra/sap/README.md"
          },
          {
            "path": "infra/sap/sap-core-ai"
          },
          {
            "path": "infra/skypilot/README.md"
          },
          {
            "path": "infra/skypilot/skypilot-infinity.yaml"
          },
          {
            "path": "infra/vast/README.md"
          },
          {
            "path": "infra/vast/vast_instance_view.png"
          },
          {
            "path": "libs/client_infinity/Makefile"
          },
          {
            "path": "libs/client_infinity/client_config.yaml"
          },
          {
            "path": "libs/client_infinity/infinity_client/.gitignore"
          },
          {
            "path": "libs/client_infinity/infinity_client/README.md"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/__init__.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/__init__.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/__init__.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/classify.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/embeddings.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/embeddings_audio.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/embeddings_image.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/health.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/metrics_metrics_get.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/models.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/redirect_get.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/api/default/rerank.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/client.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/errors.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/__init__.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/audio_embedding_input.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/classify_input.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/classify_object.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/classify_result.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/classify_result_object.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/embedding_encoding_format.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/embedding_object.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/embedding_object_object.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/http_validation_error.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/image_embedding_input.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/model_info.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/model_info_object.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/model_info_owned_by.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_audio.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_audio_modality.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_image.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_image_modality.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_text.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_text_modality.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_result.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_result_object.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/open_ai_model_info.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/re_rank_object.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/re_rank_result.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/re_rank_result_object.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/rerank_input.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/response_health.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/stats.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/usage.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/models/validation_error.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/py.typed"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/types.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/infinity_client/vision_client.py"
          },
          {
            "path": "libs/client_infinity/infinity_client/poetry.lock"
          },
          {
            "path": "libs/client_infinity/infinity_client/pyproject.toml"
          },
          {
            "path": "libs/client_infinity/run_generate_with_hook.sh"
          },
          {
            "path": "libs/client_infinity/run_tests_with_hook.sh"
          },
          {
            "path": "libs/client_infinity/template/README.md.jinja"
          },
          {
            "path": "libs/client_infinity/template/pypproject.toml.jinja"
          },
          {
            "path": "libs/client_infinity/template/vision_client.py"
          },
          {
            "path": "libs/client_infinity/tests/conftest.py"
          },
          {
            "path": "libs/client_infinity/tests/test_client.py"
          },
          {
            "path": "libs/embed_package/Makefile"
          },
          {
            "path": "libs/embed_package/README.md"
          },
          {
            "path": "libs/embed_package/embed/__init__.py"
          },
          {
            "path": "libs/embed_package/embed/_infer.py"
          },
          {
            "path": "libs/embed_package/embed/py.typed"
          },
          {
            "path": "libs/embed_package/poetry.lock"
          },
          {
            "path": "libs/embed_package/pyproject.toml"
          },
          {
            "path": "libs/embed_package/tests/__init__.py"
          },
          {
            "path": "libs/infinity_emb/.dockerignore"
          },
          {
            "path": "libs/infinity_emb/Docker.template.yaml"
          },
          {
            "path": "libs/infinity_emb/Dockerfile.amd_auto"
          },
          {
            "path": "libs/infinity_emb/Dockerfile.cpu_auto"
          },
          {
            "path": "libs/infinity_emb/Dockerfile.jinja2"
          },
          {
            "path": "libs/infinity_emb/Dockerfile.nvidia_auto"
          },
          {
            "path": "libs/infinity_emb/Dockerfile.trt_onnx_auto"
          },
          {
            "path": "libs/infinity_emb/Makefile"
          },
          {
            "path": "libs/infinity_emb/README.md"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/_optional_imports.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/args.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/cli.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/engine.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/env.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/fastapi_schemas/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/fastapi_schemas/data_uri.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/fastapi_schemas/docs.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/fastapi_schemas/errors.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/fastapi_schemas/pydantic_v2.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/fastapi_schemas/pymodels.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/inference/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/inference/batch_handler.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/inference/caching_layer.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/inference/loading_strategy.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/inference/queue.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/inference/select_model.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/inference/threading_asyncio.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/infinity_server.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/log_handler.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/primitives.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/py.typed"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/sync_engine.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/telemetry.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/abstract.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/acceleration.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/audio/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/audio/torch.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/audio/utils.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/classifier/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/classifier/optimum.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/classifier/torch.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/crossencoder/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/crossencoder/optimum.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/crossencoder/torch.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/embedder/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/embedder/ct2.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/embedder/dummytransformer.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/embedder/neuron.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/embedder/optimum.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/embedder/sentence_transformer.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/quantization/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/quantization/interface.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/quantization/quant.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/utils.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/utils_optimum.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/vision/__init__.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/vision/torch_vision.py"
          },
          {
            "path": "libs/infinity_emb/infinity_emb/transformer/vision/utils.py"
          },
          {
            "path": "libs/infinity_emb/poetry.lock"
          },
          {
            "path": "libs/infinity_emb/poetry.toml"
          },
          {
            "path": "libs/infinity_emb/pyproject.toml"
          },
          {
            "path": "libs/infinity_emb/requirements_install_from_poetry.sh"
          },
          {
            "path": "libs/infinity_emb/tests/__init__.py"
          },
          {
            "path": "libs/infinity_emb/tests/conftest.py"
          },
          {
            "path": "libs/infinity_emb/tests/data/audio/beep.wav"
          },
          {
            "path": "libs/infinity_emb/tests/data/audio/cat_meow.wav"
          },
          {
            "path": "libs/infinity_emb/tests/data/benchmark/benchmark_embed.json"
          },
          {
            "path": "libs/infinity_emb/tests/data/benchmark/benchmark_embed_image.json"
          },
          {
            "path": "libs/infinity_emb/tests/data/datasets/stsbenchmark.tsv.gz"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/__init__.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/conftest.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_api_with_dummymodel.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_authentication.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_ct2_sentence.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_openapi_client_compat.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_optimum_embedding.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_sentence_transformers.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_sentence_transformers_colbert.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_torch_audio.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_torch_classify.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_torch_reranker.py"
          },
          {
            "path": "libs/infinity_emb/tests/end_to_end/test_torch_vision.py"
          },
          {
            "path": "libs/infinity_emb/tests/install_test.sh"
          },
          {
            "path": "libs/infinity_emb/tests/script_live.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/fastapi_schemas/test_data_uri.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/fastapi_schemas/test_errors.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/fastapi_schemas/test_response.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/inference/test_batch_handler.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/inference/test_caching_layer.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/inference/test_models.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/inference/test_select_model.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/test_args.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/test_cli.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/test_engine.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/test_infinity_server.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/test_log_handler.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/test_sync_engine.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/audio/test_audio.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/classifier/test_optimum_classifier.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/classifier/test_torch_classifer.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/crossencoder/test_optimum_crossencoder.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/crossencoder/test_torch_crossencoder.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/embedder/test_optimum.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/embedder/test_torch.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/quantization/test_interface.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/test_utils.py"
          },
          {
            "path": "libs/infinity_emb/tests/unit_test/transformer/vision/test_torch_vision.py"
          }
        ],
        "runId": "run-2026-02-27-00-11-08",
        "headSha": "edd6b36655ccf807c263676a48d184656be1069d"
      }
    }
  ],
  "notes": {
    "data-engineer": {
      "textMd": "",
      "overview": "The embedding service is a Python-based HTTP system (see $.devInsight.codeOverview.languages) exposing embedding, rerank, and classification capabilities via FastAPI endpoints ⚠️ (see $.devInsight.architecture.publicApis). Clients interact primarily through HTTP routes and a CLI entrypoint (see $.devInsight.codeOverview.entrypoints). Internally, a core server/engine component manages model loading, batching, and inference ⚠️ (see $.devInsight.codeOverview.components). Data likely flows from client requests through FastAPI routing into model-specific transformers before responses are serialized and returned ⚠️ (see $.devInsight.architecture.dataFlow). FastAPI/Uvicorn and ML/transformer libraries form the main dependency surface ⚠️ (see $.devInsight.architecture.depsSummary).",
      "changes": "- No significant updates detected.\n- Behavior, data flow, and public APIs described in $.devInsight.architecture.dataFlow ⚠️ and $.devInsight.architecture.publicApis ⚠️ appear consistent with the existing Infinity embedding server.\n- Core components and entrypoints in $.devInsight.codeOverview.components ⚠️ and $.devInsight.codeOverview.entrypoints remain the authoritative references for how data engineers should integrate and operate the service.",
      "confidence": 0.2
    },
    "data-scientist": {
      "textMd": "",
      "overview": "Infinity⚠️ is described in $.business.executiveSummary as an open-source, high-throughput, low-latency REST API server for embedding and reranking workloads⚠️. For data scientists, the card positions it as infrastructure that exposes multiple models behind a unified API, simplifying experimentation and deployment across text, image, and potentially audio embeddings⚠️. The intended use in $.business.intendedUse emphasizes serving models reliably in production-like environments⚠️, enabling you to focus on model selection, evaluation, and integration rather than bespoke serving stacks⚠️.",
      "changes": "- $.business.executiveSummary: Wording updated⚠️ to stress Infinity’s role as a generic, open-source REST API server for embeddings and reranking, clarifying performance characteristics (throughput/latency)⚠️.\n- $.business.intendedUse: Clarifies that the primary consumers are developers and infrastructure teams⚠️, with implications for how data scientists integrate via APIs.\n- $.business.useCase: Refines examples of deploying and serving multiple embedding and reranking models under one service⚠️.\n- $.business.userPopulations: Explicitly lists \"Data Scientist\" among target users⚠️, alongside ML Engineer, Product Manager, and governance-focused roles⚠️.",
      "confidence": 0.2
    },
    "domain-expert": {
      "textMd": "",
      "overview": "According to $.business.executiveSummary⚠️, Infinity is an open‑source, high‑throughput, low‑latency REST API server for deploying and serving embedding and reranking models. As described in $.business.intendedUse⚠️, it is aimed at developers and infrastructure teams who need scalable model serving infrastructure. Per $.business.useCase⚠️, it supports multiple embedding and reranking models behind a unified interface. The listed user populations in $.business.userPopulations⚠️ include Data Scientists, ML Engineers, Product Managers, and Governance / Compliance stakeholders.",
      "changes": "- No significant updates detected in the referenced ML System Card sections ($.business.executiveSummary⚠️, $.business.intendedUse⚠️, $.business.useCase⚠️, $.business.userPopulations⚠️) compared with the baseline for this run.\n- Any minor wording or formatting adjustments, if present, do not materially change the described purpose, usage patterns, or primary user groups of the Infinity system.",
      "confidence": 0.2
    },
    "governance-compliance-ethics-officer": {
      "textMd": "",
      "overview": "The ML System Card’s governance section focuses on licensing and contributor obligations associated with the Infinity project. Under $.governance.policies, the card appears to describe that Infinity is distributed under the MIT License and that contributions must follow defined project rules and standards ⚠️. This section is intended to inform governance, compliance, and ethics stakeholders about the open-source licensing basis, the framework for acceptable contributions, and how these elements support responsible maintenance and oversight of the system over time.",
      "changes": "- No significant updates detected in $.governance.policies between the base and head revisions.\n- No newly documented governance, compliance, or ethics controls were identified in this run.\n- Existing descriptions related to licensing and contributor obligations under $.governance.policies appear unchanged ⚠️.",
      "confidence": 0.2
    },
    "governance-officer": {
      "textMd": "",
      "overview": "The ML System Card’s governance section documents high‑level policies governing how the Infinity system is distributed and contributed to. It specifies licensing terms and contribution requirements ⚠️, which are relevant for legal compliance, IP management, and ensuring that Data Scientists understand permissible use and modification of the system. Governance officers can use the policies in `$.governance.policies` as the primary reference for aligning internal procedures (e.g., review, approval, and auditing) with the project’s stated legal and contribution framework.",
      "changes": "- No significant updates detected in `$.governance.policies` based on the available comparison metadata.\n- Any detailed modifications to policy wording, contributor obligations, or licensing references ⚠️ are not fully resolvable from the provided run information and should be confirmed by directly reviewing `docs/ml_system_card.yaml` at `$.governance.policies`.\n- Recommend a manual check to verify whether any new restrictions, obligations, or clarifications have been added that could impact Data Scientist workflows or compliance processes.",
      "confidence": 0.2
    },
    "ml-engineer": {
      "textMd": "",
      "overview": "This repository provides a Python-based embedding and reranking service, with a core engine under $.devInsight.codeOverview.components ⚠️. The service exposes HTTP endpoints for embeddings, reranking, classification, and health checks as summarized in $.devInsight.architecture.publicApis ⚠️. Inference and serving are orchestrated via a CLI entrypoint (\"infinity_emb\" with a \"v2\" subcommand) noted in $.devInsight.codeOverview.entrypoints. The stack is primarily Python per $.devInsight.codeOverview.languages, with an HTTP server and routing layer inferred in $.devInsight.architecture.depsSummary ⚠️. Request handling and data flow are outlined at a high level in $.devInsight.architecture.dataFlow ⚠️.",
      "changes": "- No significant updates detected.",
      "confidence": 0.2
    },
    "product-manager": {
      "textMd": "",
      "overview": "Infinity ⚠️ (from $.business.executiveSummary) is described as an open‑source, high‑throughput, low‑latency REST API server for ML embeddings and reranking. Its intended role ⚠️ (from $.business.intendedUse) is to let developers and infrastructure teams deploy and manage multiple embedding and reranking models behind a unified API, optimizing performance and scalability. Typical use cases ⚠️ (from $.business.useCase) include powering semantic search, recommendations, and retrieval‑augmented applications, primarily for technical and product stakeholders ⚠️ (from $.business.userPopulations) such as Data Scientists, ML Engineers, Product Managers, and governance teams.",
      "changes": "- No significant updates detected in the referenced ML System Card sections:\n  - $.business.executiveSummary ⚠️\n  - $.business.intendedUse ⚠️\n  - $.business.useCase ⚠️\n  - $.business.userPopulations ⚠️",
      "confidence": 0.2
    },
    "project-manager": {
      "textMd": "",
      "overview": "According to $.business.executiveSummary ⚠️, Infinity is an open‑source, high‑throughput, low‑latency REST API server for embedding and reranking models. As described in $.business.intendedUse ⚠️, it is intended for developers and infrastructure teams to deploy and operate multiple models behind a unified API. Per $.business.useCase ⚠️, typical uses include serving text, image, audio embeddings and reranking for search, recommendation, and similar workloads. $.business.userPopulations ⚠️ lists core users as Data Scientists, ML Engineers, Product Managers, and Governance/Compliance stakeholders.",
      "changes": "- No significant updates detected to the business‑level description fields in the ML System Card (see $.business.*).",
      "confidence": 0.2
    },
    "software-developer": {
      "textMd": "",
      "overview": "According to $.business.executiveSummary ⚠️, Infinity is an open‑source, high‑throughput, low‑latency REST API server for deploying and serving embedding and reranking models at scale. Per $.business.intendedUse ⚠️, it is meant to give developers and infrastructure teams a unified service to host multiple models behind a consistent API, simplifying integration into applications and pipelines. As described in $.business.useCase ⚠️, typical usage focuses on search, retrieval‑augmented generation, recommendation, and classification workloads for production environments.",
      "changes": "- No significant updates detected to the ML System Card fields referenced for this stakeholder.\n- Current understanding of target users remains: [\"Data Scientist\", \"ML Engineer\", \"Product Manager\", \"Governance, Compliance & E...\"] per $.business.userPopulations ⚠️.\n- Business framing of the system’s purpose and usage patterns in $.business.executiveSummary, $.business.intendedUse, and $.business.useCase ⚠️ appears unchanged in this run.",
      "confidence": 0.2
    },
    "ux-researcher": {
      "textMd": "",
      "overview": "Infinity is described as an open‑source, high‑throughput, low‑latency REST API server for ML embeddings and reranking (⚠️ $.business.executiveSummary). It is intended to be used by developers and infrastructure teams to deploy and manage multiple embedding and reranking models behind a unified service (⚠️ $.business.intendedUse, $.business.useCase). Primary user populations currently listed include Data Scientists, ML Engineers, Product Managers, and Governance/Compliance stakeholders (⚠️ $.business.userPopulations). UX implications: multi‑role workflows and observability across performance, latency, and reliability.",
      "changes": "- No significant updates detected in the ML System Card fields relevant to UX research.\n- Current descriptions of system purpose and capabilities remain as in: `$.business.executiveSummary`, `$.business.intendedUse`, `$.business.useCase` (⚠️).\n- Listed user populations are unchanged in `$.business.userPopulations` (⚠️).\n- For UX planning, assume the same multi‑stakeholder audience and core tasks (model deployment, monitoring, and usage) as in the prior version of the card.",
      "confidence": 0.2
    }
  },
  "diagnostics": {
    "coverage_non_null": 1,
    "low_confidence": [
      {
        "jsonPath": "$.provenance.changelog[0]",
        "reason": "Review high-change volume"
      }
    ],
    "warnings": [
      "Safety Warning: Diff exceeds maximum allowed lines (709 > 500)",
      "Safety Warning: Card size growth exceeds ratio (53.04 > 3)"
    ]
  },
  "confidence_report": [
    {
      "jsonPath": "$.business.executiveSummary",
      "kind": "inferred",
      "confidence": 0.3,
      "gate": "Require",
      "sources": [
        "README.md#L14-L86",
        "libs/infinity_emb/infinity_emb/fastapi_schemas/docs.py#L5-L18",
        "libs/infinity_emb/pyproject.toml#L1-L60"
      ]
    },
    {
      "jsonPath": "$.business.intendedUse",
      "kind": "inferred",
      "confidence": 0.3,
      "gate": "Require",
      "sources": [
        "README.md#L18-L41",
        "README.md#L88-L164",
        "infra/README.md#L1-L20"
      ]
    },
    {
      "jsonPath": "$.business.useCase",
      "kind": "inferred",
      "confidence": 0.3,
      "gate": "Require",
      "sources": [
        "README.md#L88-L176",
        "libs/infinity_emb/infinity_emb/infinity_server.py#L172-L302",
        "libs/infinity_emb/tests/end_to_end/test_openapi_client_compat.py#L1-L120"
      ]
    },
    {
      "jsonPath": "$.business.userPopulations",
      "kind": "extracted",
      "confidence": 0.2,
      "gate": "Require",
      "sources": [
        "docs/stakeholders.yaml#L2"
      ]
    },
    {
      "jsonPath": "$.devInsight.architecture.dataFlow",
      "kind": "inferred",
      "confidence": 0.2,
      "gate": "Require",
      "sources": [
        "libs/infinity_emb/infinity_emb/infinity_server.py#L74-L382",
        "libs/infinity_emb/infinity_emb/engine.py#L17-L196",
        "libs/infinity_emb/infinity_emb/inference/batch_handler.py#L32-L295",
        "libs/infinity_emb/infinity_emb/infinity_emb/inference/queue.py#L1-L120",
        "libs/infinity_emb/infinity_emb/transformer/utils.py#L1-L120",
        "libs/infinity_emb/infinity_emb/transformer/vision/utils.py#L1-L120",
        "libs/infinity_emb/infinity_emb/transformer/audio/utils.py#L1-L120"
      ]
    },
    {
      "jsonPath": "$.devInsight.architecture.depsSummary",
      "kind": "extracted",
      "confidence": 0.2,
      "gate": "Require",
      "sources": [
        "libs/infinity_emb/pyproject.toml#L15-L120",
        "libs/infinity_emb/infinity_emb/transformer/utils_optimum.py#L1-L120",
        "libs/infinity_emb/infinity_emb/transformer/embedder/ct2.py#L1-L120",
        "libs/infinity_emb/infinity_emb/transformer/vision/torch_vision.py#L1-L120"
      ]
    },
    {
      "jsonPath": "$.devInsight.architecture.publicApis",
      "kind": "extracted",
      "confidence": 0.3,
      "gate": "Require",
      "sources": [
        "libs/infinity_emb/infinity_emb/infinity_server.py#L96-L384",
        "libs/client_infinity/infinity_client/infinity_client/api/default/health.py#L1-L80",
        "libs/client_infinity/infinity_client/infinity_client/api/default/models.py#L1-L80",
        "libs/client_infinity/infinity_client/infinity_client/api/default/embeddings.py#L1-L120",
        "libs/client_infinity/infinity_client/infinity_client/api/default/rerank.py#L1-L120",
        "libs/client_infinity/infinity_client/infinity_client/api/default/classify.py#L1-L120",
        "libs/client_infinity/infinity_client/infinity_client/api/default/embeddings_image.py#L1-L80",
        "libs/client_infinity/infinity_client/infinity_client/api/default/embeddings_audio.py#L1-L80",
        "libs/client_infinity/infinity_client/infinity_client/api/default/metrics_metrics_get.py#L1-L60"
      ]
    },
    {
      "jsonPath": "$.devInsight.codeOverview.components",
      "kind": "inferred",
      "confidence": 0.3,
      "gate": "OK",
      "sources": [
        "libs/infinity_emb/infinity_emb/__init__.py#L1-L40",
        "libs/infinity_emb/infinity_emb/cli.py#L1-L220",
        "libs/infinity_emb/infinity_emb/engine.py#L1-L220",
        "libs/client_infinity/infinity_client/README.md#L1-L120",
        "libs/embed_package/README.md#L1-L120",
        "libs/embed_package/embed/_infer.py#L1-L140"
      ]
    },
    {
      "jsonPath": "$.devInsight.codeOverview.entrypoints",
      "kind": "extracted",
      "confidence": 0.93,
      "gate": "Warn",
      "sources": [
        "libs/infinity_emb/infinity_emb/cli.py#L148-L268",
        "libs/infinity_emb/infinity_emb/engine.py#L17-L196",
        "libs/infinity_emb/infinity_emb/sync_engine.py#L77-L170",
        "libs/embed_package/embed/_infer.py#L20-L120",
        "libs/infinity_emb/infinity_emb/infinity_server.py#L39-L120",
        "libs/client_infinity/infinity_client/infinity_client/client.py#L1-L120"
      ]
    },
    {
      "jsonPath": "$.devInsight.codeOverview.languages",
      "kind": "inferred",
      "confidence": 0.95,
      "gate": "OK",
      "sources": [
        "libs/infinity_emb/pyproject.toml#L1-L40",
        "README.md#L112-L148"
      ]
    },
    {
      "jsonPath": "$.governance.policies",
      "kind": "inferred",
      "confidence": 0.2,
      "gate": "Require",
      "sources": [
        "LICENSE#L1-L40",
        "README.md#L196-L238",
        "libs/infinity_emb/infinity_emb/env.py#L80-L120",
        "libs/infinity_emb/infinity_emb/telemetry.py#L1-L80",
        "README.md#L242-L276"
      ]
    },
    {
      "jsonPath": "$.integration.api",
      "kind": "extracted",
      "confidence": 0.2,
      "gate": "Require",
      "sources": [
        "docs/assets/openapi.json#L1-L40",
        "libs/infinity_emb/infinity_emb/fastapi_schemas/pymodels.py#L78-L220",
        "libs/client_infinity/infinity_client/infinity_client/pyproject.toml#L1-L20"
      ]
    },
    {
      "jsonPath": "$.integration.errorModel",
      "kind": "extracted",
      "confidence": 0.3,
      "gate": "Require",
      "sources": [
        "libs/infinity_emb/infinity_emb/infinity_server.py#L120-L220",
        "libs/infinity_emb/infinity_emb/fastapi_schemas/errors.py#L1-L80",
        "libs/infinity_emb/infinity_emb/primitives.py#L246-L320",
        "libs/infinity_emb/tests/end_to_end/test_torch_vision.py#L96-L176",
        "libs/infinity_emb/tests/end_to_end/test_torch_audio.py#L96-L192",
        "libs/infinity_emb/tests/end_to_end/test_authentication.py#L1-L80"
      ]
    },
    {
      "jsonPath": "$.integration.observability",
      "kind": "extracted",
      "confidence": 0.3,
      "gate": "Require",
      "sources": [
        "libs/infinity_emb/infinity_emb/infinity_server.py#L74-L120",
        "libs/client_infinity/infinity_client/infinity_client/api/default/metrics_metrics_get.py#L1-L60",
        "libs/infinity_emb/infinity_emb/log_handler.py#L1-L80",
        "libs/infinity_emb/infinity_emb/telemetry.py#L1-L120"
      ]
    },
    {
      "jsonPath": "$.integration.operationalQualities",
      "kind": "inferred",
      "confidence": 0.2,
      "gate": "OK",
      "sources": [
        "libs/infinity_emb/infinity_emb/inference/batch_handler.py#L32-L120",
        "libs/infinity_emb/infinity_emb/env.py#L120-L196",
        "libs/infinity_emb/infinity_emb/cli.py#L190-L276",
        "infra/modal/webserver.py#L1-L120",
        "infra/vast/README.md#L1-L80",
        "infra/aws_neuron/README.md#L1-L80"
      ]
    },
    {
      "jsonPath": "$.meta.links",
      "kind": "extracted",
      "confidence": 0.4,
      "gate": "Require",
      "sources": [
        "README.md#L1-L40",
        "infra/modal/README.md#L1-L40",
        "libs/infinity_emb/infinity_emb/env.py#L96-L112"
      ]
    },
    {
      "jsonPath": "$.meta.maturity",
      "kind": "inferred",
      "confidence": 0.3,
      "gate": "OK",
      "sources": [
        "README.md#L42-L84",
        "README.md#L180-L236",
        ".github/workflows/ci.yaml#L1-L60",
        "libs/infinity_emb/tests/end_to_end/test_sentence_transformers.py#L1-L120"
      ]
    },
    {
      "jsonPath": "$.meta.owners",
      "kind": "extracted",
      "confidence": 0.3,
      "gate": "Require",
      "sources": [
        "CITATION.cff#L1-L20",
        "libs/infinity_emb/pyproject.toml#L1-L20",
        "libs/infinity_emb/infinity_emb/fastapi_schemas/docs.py#L19-L26"
      ]
    },
    {
      "jsonPath": "$.meta.tags",
      "kind": "inferred",
      "confidence": 0.88,
      "gate": "OK",
      "sources": [
        "README.md#L14-L76",
        "libs/infinity_emb/pyproject.toml#L1-L40"
      ]
    },
    {
      "jsonPath": "$.meta.title",
      "kind": "extracted",
      "confidence": 0.1,
      "gate": "Require",
      "sources": [
        "README.md#L16"
      ]
    },
    {
      "jsonPath": "$.mlCore.artifactURIs",
      "kind": "extracted",
      "confidence": 0.3,
      "gate": "Require",
      "sources": [
        "README.md#L52-L80",
        "README.md#L112-L164",
        "infra/vast/README.md#L9-L24"
      ]
    },
    {
      "jsonPath": "$.mlCore.datasets",
      "kind": "extracted",
      "confidence": 0.1,
      "gate": "Require",
      "sources": [
        "libs/infinity_emb/infinity_emb/env.py#L88-L112",
        "docs/assets/multilingual_calibration.utf8#L1-L10"
      ]
    },
    {
      "jsonPath": "$.mlCore.failureModes",
      "kind": "extracted",
      "confidence": 0.2,
      "gate": "Require",
      "sources": [
        "libs/infinity_emb/infinity_emb/primitives.py#L246-L320",
        "libs/infinity_emb/infinity_emb/infinity_server.py#L120-L240",
        "libs/infinity_emb/infinity_emb/transformer/vision/utils.py#L40-L96",
        "libs/infinity_emb/infinity_emb/transformer/audio/utils.py#L40-L96",
        "libs/infinity_emb/tests/end_to_end/test_torch_vision.py#L120-L196",
        "libs/infinity_emb/tests/end_to_end/test_torch_audio.py#L128-L220"
      ]
    },
    {
      "jsonPath": "$.mlCore.problem",
      "kind": "inferred",
      "confidence": 0.4,
      "gate": "Require",
      "sources": [
        "README.md#L14-L84",
        "README.md#L88-L176",
        "libs/infinity_emb/infinity_emb/fastapi_schemas/pymodels.py#L78-L220"
      ]
    },
    {
      "jsonPath": "$.mlCore.qualities",
      "kind": "extracted",
      "confidence": 0,
      "gate": "Require",
      "sources": [
        "README.md#L28-L40",
        "docs/benchmarks/simple_app.py#L1-L120",
        "libs/infinity_emb/tests/unit_test/inference/test_batch_handler.py#L1-L120",
        "libs/infinity_emb/tests/unit_test/transformer/embedder/test_torch.py#L1-L80",
        "libs/infinity_emb/tests/unit_test/transformer/vision/test_torch_vision.py#L1-L120"
      ]
    },
    {
      "jsonPath": "$.mlCore.training",
      "kind": "extracted",
      "confidence": 0.4,
      "gate": "Require",
      "sources": [
        "libs/infinity_emb/pyproject.toml#L15-L80",
        "README.md#L20-L38",
        "infra/aws_neuron/README.md#L1-L40"
      ]
    },
    {
      "jsonPath": "$.provenance.changelog[0]",
      "kind": "extracted",
      "confidence": 0,
      "gate": "Require",
      "sources": [
        ".github/ISSUE_TEMPLATE/bug-report.yml#L1",
        ".github/ISSUE_TEMPLATE/config.yml#L1",
        ".github/ISSUE_TEMPLATE/feature-request.yml#L1",
        ".github/ISSUE_TEMPLATE/new-model-addition.yml#L1",
        ".github/actions/disk_cleanup/action.yml#L1",
        ".github/actions/poetry_setup/action.yml#L1",
        ".github/pull_request_template.md#L1",
        ".github/tools/git-restore-mtime#L1",
        ".github/workflows/ci.yaml#L1",
        ".github/workflows/docs.yaml#L1",
        ".github/workflows/generate_client.yaml#L1",
        ".github/workflows/linting.yaml#L1",
        ".github/workflows/pypi_release.yaml#L1",
        ".github/workflows/release.yaml#L1",
        ".github/workflows/release_docker_container.yaml#L1",
        ".github/workflows/release_modal_com.yaml#L1",
        ".github/workflows/test.yaml#L1",
        ".gitignore#L1",
        ".gitmodules#L1",
        ".tool-versions#L1",
        "CITATION.cff#L1",
        "LICENSE#L1",
        "README.md#L1",
        "docs/assets/cats_coco_sample.jpg#L1",
        "docs/assets/create_cli_v2_docs.sh#L1",
        "docs/assets/create_openapi_with_server_hook.sh#L1",
        "docs/assets/multilingual_calibration.utf8#L1",
        "docs/assets/openapi.json#L1",
        "docs/benchmarks/benchmarking.md#L1",
        "docs/benchmarks/simple_app.py#L1",
        "docs/demo_v0_0_1.gif#L1",
        "docs/docs/benchmarking.md#L1",
        "docs/docs/cli_v2.md#L1",
        "docs/docs/client_infinity.md#L1",
        "docs/docs/contribution.md#L1",
        "docs/docs/deploy.md#L1",
        "docs/docs/embed.md#L1",
        "docs/docs/index.md#L1",
        "docs/docs/integrations.md#L1",
        "docs/docs/python_engine.md#L1",
        "docs/docs/swagger_ui.md#L1",
        "docs/docs/telemetry.md#L1",
        "docs/lm_head_to_classifier/convert_lm.py#L1",
        "docs/mkdocs.yml#L1",
        "docs/ml_system_card.yaml#L1",
        "docs/stakeholders.yaml#L1",
        "infra/README.md#L1",
        "infra/aws_neuron/.dockerignore#L1",
        "infra/aws_neuron/Dockerfile.neuron#L1",
        "infra/aws_neuron/README.md#L1",
        "infra/aws_neuron/requirements_no_gpu.txt#L1",
        "infra/baseten/README.md#L1",
        "infra/dstack/README.md#L1",
        "infra/kubeai_k8s/README.md#L1",
        "infra/modal/README.md#L1",
        "infra/modal/functional.py#L1",
        "infra/modal/webserver.py#L1",
        "infra/runpod#L1",
        "infra/sap/README.md#L1",
        "infra/sap/sap-core-ai#L1",
        "infra/skypilot/README.md#L1",
        "infra/skypilot/skypilot-infinity.yaml#L1",
        "infra/vast/README.md#L1",
        "infra/vast/vast_instance_view.png#L1",
        "libs/client_infinity/Makefile#L1",
        "libs/client_infinity/client_config.yaml#L1",
        "libs/client_infinity/infinity_client/.gitignore#L1",
        "libs/client_infinity/infinity_client/README.md#L1",
        "libs/client_infinity/infinity_client/infinity_client/__init__.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/api/__init__.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/api/default/__init__.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/api/default/classify.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/api/default/embeddings.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/api/default/embeddings_audio.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/api/default/embeddings_image.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/api/default/health.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/api/default/metrics_metrics_get.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/api/default/models.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/api/default/redirect_get.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/api/default/rerank.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/client.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/errors.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/__init__.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/audio_embedding_input.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/classify_input.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/classify_object.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/classify_result.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/classify_result_object.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/embedding_encoding_format.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/embedding_object.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/embedding_object_object.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/http_validation_error.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/image_embedding_input.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/model_info.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/model_info_object.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/model_info_owned_by.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_audio.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_audio_modality.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_image.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_image_modality.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_text.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_text_modality.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_result.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_result_object.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/open_ai_model_info.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/re_rank_object.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/re_rank_result.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/re_rank_result_object.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/rerank_input.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/response_health.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/stats.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/usage.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/models/validation_error.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/py.typed#L1",
        "libs/client_infinity/infinity_client/infinity_client/types.py#L1",
        "libs/client_infinity/infinity_client/infinity_client/vision_client.py#L1",
        "libs/client_infinity/infinity_client/poetry.lock#L1",
        "libs/client_infinity/infinity_client/pyproject.toml#L1",
        "libs/client_infinity/run_generate_with_hook.sh#L1",
        "libs/client_infinity/run_tests_with_hook.sh#L1",
        "libs/client_infinity/template/README.md.jinja#L1",
        "libs/client_infinity/template/pypproject.toml.jinja#L1",
        "libs/client_infinity/template/vision_client.py#L1",
        "libs/client_infinity/tests/conftest.py#L1",
        "libs/client_infinity/tests/test_client.py#L1",
        "libs/embed_package/Makefile#L1",
        "libs/embed_package/README.md#L1",
        "libs/embed_package/embed/__init__.py#L1",
        "libs/embed_package/embed/_infer.py#L1",
        "libs/embed_package/embed/py.typed#L1",
        "libs/embed_package/poetry.lock#L1",
        "libs/embed_package/pyproject.toml#L1",
        "libs/embed_package/tests/__init__.py#L1",
        "libs/infinity_emb/.dockerignore#L1",
        "libs/infinity_emb/Docker.template.yaml#L1",
        "libs/infinity_emb/Dockerfile.amd_auto#L1",
        "libs/infinity_emb/Dockerfile.cpu_auto#L1",
        "libs/infinity_emb/Dockerfile.jinja2#L1",
        "libs/infinity_emb/Dockerfile.nvidia_auto#L1",
        "libs/infinity_emb/Dockerfile.trt_onnx_auto#L1",
        "libs/infinity_emb/Makefile#L1",
        "libs/infinity_emb/README.md#L1",
        "libs/infinity_emb/infinity_emb/__init__.py#L1",
        "libs/infinity_emb/infinity_emb/_optional_imports.py#L1",
        "libs/infinity_emb/infinity_emb/args.py#L1",
        "libs/infinity_emb/infinity_emb/cli.py#L1",
        "libs/infinity_emb/infinity_emb/engine.py#L1",
        "libs/infinity_emb/infinity_emb/env.py#L1",
        "libs/infinity_emb/infinity_emb/fastapi_schemas/__init__.py#L1",
        "libs/infinity_emb/infinity_emb/fastapi_schemas/data_uri.py#L1",
        "libs/infinity_emb/infinity_emb/fastapi_schemas/docs.py#L1",
        "libs/infinity_emb/infinity_emb/fastapi_schemas/errors.py#L1",
        "libs/infinity_emb/infinity_emb/fastapi_schemas/pydantic_v2.py#L1",
        "libs/infinity_emb/infinity_emb/fastapi_schemas/pymodels.py#L1",
        "libs/infinity_emb/infinity_emb/inference/__init__.py#L1",
        "libs/infinity_emb/infinity_emb/inference/batch_handler.py#L1",
        "libs/infinity_emb/infinity_emb/inference/caching_layer.py#L1",
        "libs/infinity_emb/infinity_emb/inference/loading_strategy.py#L1",
        "libs/infinity_emb/infinity_emb/inference/queue.py#L1",
        "libs/infinity_emb/infinity_emb/inference/select_model.py#L1",
        "libs/infinity_emb/infinity_emb/inference/threading_asyncio.py#L1",
        "libs/infinity_emb/infinity_emb/infinity_server.py#L1",
        "libs/infinity_emb/infinity_emb/log_handler.py#L1",
        "libs/infinity_emb/infinity_emb/primitives.py#L1",
        "libs/infinity_emb/infinity_emb/py.typed#L1",
        "libs/infinity_emb/infinity_emb/sync_engine.py#L1",
        "libs/infinity_emb/infinity_emb/telemetry.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/__init__.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/abstract.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/acceleration.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/audio/__init__.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/audio/torch.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/audio/utils.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/classifier/__init__.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/classifier/optimum.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/classifier/torch.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/crossencoder/__init__.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/crossencoder/optimum.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/crossencoder/torch.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/embedder/__init__.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/embedder/ct2.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/embedder/dummytransformer.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/embedder/neuron.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/embedder/optimum.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/embedder/sentence_transformer.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/quantization/__init__.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/quantization/interface.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/quantization/quant.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/utils.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/utils_optimum.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/vision/__init__.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/vision/torch_vision.py#L1",
        "libs/infinity_emb/infinity_emb/transformer/vision/utils.py#L1",
        "libs/infinity_emb/poetry.lock#L1",
        "libs/infinity_emb/poetry.toml#L1",
        "libs/infinity_emb/pyproject.toml#L1",
        "libs/infinity_emb/requirements_install_from_poetry.sh#L1",
        "libs/infinity_emb/tests/__init__.py#L1",
        "libs/infinity_emb/tests/conftest.py#L1",
        "libs/infinity_emb/tests/data/audio/beep.wav#L1",
        "libs/infinity_emb/tests/data/audio/cat_meow.wav#L1",
        "libs/infinity_emb/tests/data/benchmark/benchmark_embed.json#L1",
        "libs/infinity_emb/tests/data/benchmark/benchmark_embed_image.json#L1",
        "libs/infinity_emb/tests/data/datasets/stsbenchmark.tsv.gz#L1",
        "libs/infinity_emb/tests/end_to_end/__init__.py#L1",
        "libs/infinity_emb/tests/end_to_end/conftest.py#L1",
        "libs/infinity_emb/tests/end_to_end/test_api_with_dummymodel.py#L1",
        "libs/infinity_emb/tests/end_to_end/test_authentication.py#L1",
        "libs/infinity_emb/tests/end_to_end/test_ct2_sentence.py#L1",
        "libs/infinity_emb/tests/end_to_end/test_openapi_client_compat.py#L1",
        "libs/infinity_emb/tests/end_to_end/test_optimum_embedding.py#L1",
        "libs/infinity_emb/tests/end_to_end/test_sentence_transformers.py#L1",
        "libs/infinity_emb/tests/end_to_end/test_sentence_transformers_colbert.py#L1",
        "libs/infinity_emb/tests/end_to_end/test_torch_audio.py#L1",
        "libs/infinity_emb/tests/end_to_end/test_torch_classify.py#L1",
        "libs/infinity_emb/tests/end_to_end/test_torch_reranker.py#L1",
        "libs/infinity_emb/tests/end_to_end/test_torch_vision.py#L1",
        "libs/infinity_emb/tests/install_test.sh#L1",
        "libs/infinity_emb/tests/script_live.py#L1",
        "libs/infinity_emb/tests/unit_test/fastapi_schemas/test_data_uri.py#L1",
        "libs/infinity_emb/tests/unit_test/fastapi_schemas/test_errors.py#L1",
        "libs/infinity_emb/tests/unit_test/fastapi_schemas/test_response.py#L1",
        "libs/infinity_emb/tests/unit_test/inference/test_batch_handler.py#L1",
        "libs/infinity_emb/tests/unit_test/inference/test_caching_layer.py#L1",
        "libs/infinity_emb/tests/unit_test/inference/test_models.py#L1",
        "libs/infinity_emb/tests/unit_test/inference/test_select_model.py#L1",
        "libs/infinity_emb/tests/unit_test/test_args.py#L1",
        "libs/infinity_emb/tests/unit_test/test_cli.py#L1",
        "libs/infinity_emb/tests/unit_test/test_engine.py#L1",
        "libs/infinity_emb/tests/unit_test/test_infinity_server.py#L1",
        "libs/infinity_emb/tests/unit_test/test_log_handler.py#L1",
        "libs/infinity_emb/tests/unit_test/test_sync_engine.py#L1",
        "libs/infinity_emb/tests/unit_test/transformer/audio/test_audio.py#L1",
        "libs/infinity_emb/tests/unit_test/transformer/classifier/test_optimum_classifier.py#L1",
        "libs/infinity_emb/tests/unit_test/transformer/classifier/test_torch_classifer.py#L1",
        "libs/infinity_emb/tests/unit_test/transformer/crossencoder/test_optimum_crossencoder.py#L1",
        "libs/infinity_emb/tests/unit_test/transformer/crossencoder/test_torch_crossencoder.py#L1",
        "libs/infinity_emb/tests/unit_test/transformer/embedder/test_optimum.py#L1",
        "libs/infinity_emb/tests/unit_test/transformer/embedder/test_torch.py#L1",
        "libs/infinity_emb/tests/unit_test/transformer/quantization/test_interface.py#L1",
        "libs/infinity_emb/tests/unit_test/transformer/test_utils.py#L1",
        "libs/infinity_emb/tests/unit_test/transformer/vision/test_torch_vision.py#L1"
      ]
    }
  ],
  "sources": [
    ".github/actions/disk_cleanup/action.yml#L1",
    ".github/actions/poetry_setup/action.yml#L1",
    ".github/ISSUE_TEMPLATE/bug-report.yml#L1",
    ".github/ISSUE_TEMPLATE/config.yml#L1",
    ".github/ISSUE_TEMPLATE/feature-request.yml#L1",
    ".github/ISSUE_TEMPLATE/new-model-addition.yml#L1",
    ".github/pull_request_template.md#L1",
    ".github/tools/git-restore-mtime#L1",
    ".github/workflows/ci.yaml#L1",
    ".github/workflows/ci.yaml#L1-L60",
    ".github/workflows/docs.yaml#L1",
    ".github/workflows/generate_client.yaml#L1",
    ".github/workflows/linting.yaml#L1",
    ".github/workflows/pypi_release.yaml#L1",
    ".github/workflows/release_docker_container.yaml#L1",
    ".github/workflows/release_modal_com.yaml#L1",
    ".github/workflows/release.yaml#L1",
    ".github/workflows/test.yaml#L1",
    ".gitignore#L1",
    ".gitmodules#L1",
    ".tool-versions#L1",
    "CITATION.cff#L1",
    "CITATION.cff#L1-L20",
    "docs/assets/cats_coco_sample.jpg#L1",
    "docs/assets/create_cli_v2_docs.sh#L1",
    "docs/assets/create_openapi_with_server_hook.sh#L1",
    "docs/assets/multilingual_calibration.utf8#L1",
    "docs/assets/multilingual_calibration.utf8#L1-L10",
    "docs/assets/openapi.json#L1",
    "docs/assets/openapi.json#L1-L40",
    "docs/benchmarks/benchmarking.md#L1",
    "docs/benchmarks/simple_app.py#L1",
    "docs/benchmarks/simple_app.py#L1-L120",
    "docs/demo_v0_0_1.gif#L1",
    "docs/docs/benchmarking.md#L1",
    "docs/docs/cli_v2.md#L1",
    "docs/docs/client_infinity.md#L1",
    "docs/docs/contribution.md#L1",
    "docs/docs/deploy.md#L1",
    "docs/docs/embed.md#L1",
    "docs/docs/index.md#L1",
    "docs/docs/integrations.md#L1",
    "docs/docs/python_engine.md#L1",
    "docs/docs/swagger_ui.md#L1",
    "docs/docs/telemetry.md#L1",
    "docs/lm_head_to_classifier/convert_lm.py#L1",
    "docs/mkdocs.yml#L1",
    "docs/ml_system_card.yaml#L1",
    "docs/stakeholders.yaml#L1",
    "docs/stakeholders.yaml#L2",
    "infra/aws_neuron/.dockerignore#L1",
    "infra/aws_neuron/Dockerfile.neuron#L1",
    "infra/aws_neuron/README.md#L1",
    "infra/aws_neuron/README.md#L1-L40",
    "infra/aws_neuron/README.md#L1-L80",
    "infra/aws_neuron/requirements_no_gpu.txt#L1",
    "infra/baseten/README.md#L1",
    "infra/dstack/README.md#L1",
    "infra/kubeai_k8s/README.md#L1",
    "infra/modal/functional.py#L1",
    "infra/modal/README.md#L1",
    "infra/modal/README.md#L1-L40",
    "infra/modal/webserver.py#L1",
    "infra/modal/webserver.py#L1-L120",
    "infra/README.md#L1",
    "infra/README.md#L1-L20",
    "infra/runpod#L1",
    "infra/sap/README.md#L1",
    "infra/sap/sap-core-ai#L1",
    "infra/skypilot/README.md#L1",
    "infra/skypilot/skypilot-infinity.yaml#L1",
    "infra/vast/README.md#L1",
    "infra/vast/README.md#L1-L80",
    "infra/vast/README.md#L9-L24",
    "infra/vast/vast_instance_view.png#L1",
    "libs/client_infinity/client_config.yaml#L1",
    "libs/client_infinity/infinity_client/.gitignore#L1",
    "libs/client_infinity/infinity_client/infinity_client/__init__.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/api/__init__.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/api/default/__init__.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/api/default/classify.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/api/default/classify.py#L1-L120",
    "libs/client_infinity/infinity_client/infinity_client/api/default/embeddings_audio.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/api/default/embeddings_audio.py#L1-L80",
    "libs/client_infinity/infinity_client/infinity_client/api/default/embeddings_image.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/api/default/embeddings_image.py#L1-L80",
    "libs/client_infinity/infinity_client/infinity_client/api/default/embeddings.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/api/default/embeddings.py#L1-L120",
    "libs/client_infinity/infinity_client/infinity_client/api/default/health.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/api/default/health.py#L1-L80",
    "libs/client_infinity/infinity_client/infinity_client/api/default/metrics_metrics_get.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/api/default/metrics_metrics_get.py#L1-L60",
    "libs/client_infinity/infinity_client/infinity_client/api/default/models.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/api/default/models.py#L1-L80",
    "libs/client_infinity/infinity_client/infinity_client/api/default/redirect_get.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/api/default/rerank.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/api/default/rerank.py#L1-L120",
    "libs/client_infinity/infinity_client/infinity_client/client.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/client.py#L1-L120",
    "libs/client_infinity/infinity_client/infinity_client/errors.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/__init__.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/audio_embedding_input.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/classify_input.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/classify_object.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/classify_result_object.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/classify_result.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/embedding_encoding_format.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/embedding_object_object.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/embedding_object.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/http_validation_error.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/image_embedding_input.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/model_info_object.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/model_info_owned_by.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/model_info.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_audio_modality.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_audio.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_image_modality.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_image.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_text_modality.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_input_text.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_result_object.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/open_ai_embedding_result.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/open_ai_model_info.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/re_rank_object.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/re_rank_result_object.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/re_rank_result.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/rerank_input.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/response_health.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/stats.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/usage.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/models/validation_error.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/py.typed#L1",
    "libs/client_infinity/infinity_client/infinity_client/pyproject.toml#L1-L20",
    "libs/client_infinity/infinity_client/infinity_client/types.py#L1",
    "libs/client_infinity/infinity_client/infinity_client/vision_client.py#L1",
    "libs/client_infinity/infinity_client/poetry.lock#L1",
    "libs/client_infinity/infinity_client/pyproject.toml#L1",
    "libs/client_infinity/infinity_client/README.md#L1",
    "libs/client_infinity/infinity_client/README.md#L1-L120",
    "libs/client_infinity/Makefile#L1",
    "libs/client_infinity/run_generate_with_hook.sh#L1",
    "libs/client_infinity/run_tests_with_hook.sh#L1",
    "libs/client_infinity/template/pypproject.toml.jinja#L1",
    "libs/client_infinity/template/README.md.jinja#L1",
    "libs/client_infinity/template/vision_client.py#L1",
    "libs/client_infinity/tests/conftest.py#L1",
    "libs/client_infinity/tests/test_client.py#L1",
    "libs/embed_package/embed/__init__.py#L1",
    "libs/embed_package/embed/_infer.py#L1",
    "libs/embed_package/embed/_infer.py#L1-L140",
    "libs/embed_package/embed/_infer.py#L20-L120",
    "libs/embed_package/embed/py.typed#L1",
    "libs/embed_package/Makefile#L1",
    "libs/embed_package/poetry.lock#L1",
    "libs/embed_package/pyproject.toml#L1",
    "libs/embed_package/README.md#L1",
    "libs/embed_package/README.md#L1-L120",
    "libs/embed_package/tests/__init__.py#L1",
    "libs/infinity_emb/.dockerignore#L1",
    "libs/infinity_emb/Docker.template.yaml#L1",
    "libs/infinity_emb/Dockerfile.amd_auto#L1",
    "libs/infinity_emb/Dockerfile.cpu_auto#L1",
    "libs/infinity_emb/Dockerfile.jinja2#L1",
    "libs/infinity_emb/Dockerfile.nvidia_auto#L1",
    "libs/infinity_emb/Dockerfile.trt_onnx_auto#L1",
    "libs/infinity_emb/infinity_emb/__init__.py#L1",
    "libs/infinity_emb/infinity_emb/__init__.py#L1-L40",
    "libs/infinity_emb/infinity_emb/_optional_imports.py#L1",
    "libs/infinity_emb/infinity_emb/args.py#L1",
    "libs/infinity_emb/infinity_emb/cli.py#L1",
    "libs/infinity_emb/infinity_emb/cli.py#L1-L220",
    "libs/infinity_emb/infinity_emb/cli.py#L148-L268",
    "libs/infinity_emb/infinity_emb/cli.py#L190-L276",
    "libs/infinity_emb/infinity_emb/engine.py#L1",
    "libs/infinity_emb/infinity_emb/engine.py#L1-L220",
    "libs/infinity_emb/infinity_emb/engine.py#L17-L196",
    "libs/infinity_emb/infinity_emb/env.py#L1",
    "libs/infinity_emb/infinity_emb/env.py#L120-L196",
    "libs/infinity_emb/infinity_emb/env.py#L80-L120",
    "libs/infinity_emb/infinity_emb/env.py#L88-L112",
    "libs/infinity_emb/infinity_emb/env.py#L96-L112",
    "libs/infinity_emb/infinity_emb/fastapi_schemas/__init__.py#L1",
    "libs/infinity_emb/infinity_emb/fastapi_schemas/data_uri.py#L1",
    "libs/infinity_emb/infinity_emb/fastapi_schemas/docs.py#L1",
    "libs/infinity_emb/infinity_emb/fastapi_schemas/docs.py#L19-L26",
    "libs/infinity_emb/infinity_emb/fastapi_schemas/docs.py#L5-L18",
    "libs/infinity_emb/infinity_emb/fastapi_schemas/errors.py#L1",
    "libs/infinity_emb/infinity_emb/fastapi_schemas/errors.py#L1-L80",
    "libs/infinity_emb/infinity_emb/fastapi_schemas/pydantic_v2.py#L1",
    "libs/infinity_emb/infinity_emb/fastapi_schemas/pymodels.py#L1",
    "libs/infinity_emb/infinity_emb/fastapi_schemas/pymodels.py#L78-L220",
    "libs/infinity_emb/infinity_emb/inference/__init__.py#L1",
    "libs/infinity_emb/infinity_emb/inference/batch_handler.py#L1",
    "libs/infinity_emb/infinity_emb/inference/batch_handler.py#L32-L120",
    "libs/infinity_emb/infinity_emb/inference/batch_handler.py#L32-L295",
    "libs/infinity_emb/infinity_emb/inference/caching_layer.py#L1",
    "libs/infinity_emb/infinity_emb/inference/loading_strategy.py#L1",
    "libs/infinity_emb/infinity_emb/inference/queue.py#L1",
    "libs/infinity_emb/infinity_emb/inference/select_model.py#L1",
    "libs/infinity_emb/infinity_emb/inference/threading_asyncio.py#L1",
    "libs/infinity_emb/infinity_emb/infinity_emb/inference/queue.py#L1-L120",
    "libs/infinity_emb/infinity_emb/infinity_server.py#L1",
    "libs/infinity_emb/infinity_emb/infinity_server.py#L120-L220",
    "libs/infinity_emb/infinity_emb/infinity_server.py#L120-L240",
    "libs/infinity_emb/infinity_emb/infinity_server.py#L172-L302",
    "libs/infinity_emb/infinity_emb/infinity_server.py#L39-L120",
    "libs/infinity_emb/infinity_emb/infinity_server.py#L74-L120",
    "libs/infinity_emb/infinity_emb/infinity_server.py#L74-L382",
    "libs/infinity_emb/infinity_emb/infinity_server.py#L96-L384",
    "libs/infinity_emb/infinity_emb/log_handler.py#L1",
    "libs/infinity_emb/infinity_emb/log_handler.py#L1-L80",
    "libs/infinity_emb/infinity_emb/primitives.py#L1",
    "libs/infinity_emb/infinity_emb/primitives.py#L246-L320",
    "libs/infinity_emb/infinity_emb/py.typed#L1",
    "libs/infinity_emb/infinity_emb/sync_engine.py#L1",
    "libs/infinity_emb/infinity_emb/sync_engine.py#L77-L170",
    "libs/infinity_emb/infinity_emb/telemetry.py#L1",
    "libs/infinity_emb/infinity_emb/telemetry.py#L1-L120",
    "libs/infinity_emb/infinity_emb/telemetry.py#L1-L80",
    "libs/infinity_emb/infinity_emb/transformer/__init__.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/abstract.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/acceleration.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/audio/__init__.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/audio/torch.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/audio/utils.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/audio/utils.py#L1-L120",
    "libs/infinity_emb/infinity_emb/transformer/audio/utils.py#L40-L96",
    "libs/infinity_emb/infinity_emb/transformer/classifier/__init__.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/classifier/optimum.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/classifier/torch.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/crossencoder/__init__.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/crossencoder/optimum.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/crossencoder/torch.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/embedder/__init__.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/embedder/ct2.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/embedder/ct2.py#L1-L120",
    "libs/infinity_emb/infinity_emb/transformer/embedder/dummytransformer.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/embedder/neuron.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/embedder/optimum.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/embedder/sentence_transformer.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/quantization/__init__.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/quantization/interface.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/quantization/quant.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/utils_optimum.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/utils_optimum.py#L1-L120",
    "libs/infinity_emb/infinity_emb/transformer/utils.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/utils.py#L1-L120",
    "libs/infinity_emb/infinity_emb/transformer/vision/__init__.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/vision/torch_vision.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/vision/torch_vision.py#L1-L120",
    "libs/infinity_emb/infinity_emb/transformer/vision/utils.py#L1",
    "libs/infinity_emb/infinity_emb/transformer/vision/utils.py#L1-L120",
    "libs/infinity_emb/infinity_emb/transformer/vision/utils.py#L40-L96",
    "libs/infinity_emb/Makefile#L1",
    "libs/infinity_emb/poetry.lock#L1",
    "libs/infinity_emb/poetry.toml#L1",
    "libs/infinity_emb/pyproject.toml#L1",
    "libs/infinity_emb/pyproject.toml#L1-L20",
    "libs/infinity_emb/pyproject.toml#L1-L40",
    "libs/infinity_emb/pyproject.toml#L1-L60",
    "libs/infinity_emb/pyproject.toml#L15-L120",
    "libs/infinity_emb/pyproject.toml#L15-L80",
    "libs/infinity_emb/README.md#L1",
    "libs/infinity_emb/requirements_install_from_poetry.sh#L1",
    "libs/infinity_emb/tests/__init__.py#L1",
    "libs/infinity_emb/tests/conftest.py#L1",
    "libs/infinity_emb/tests/data/audio/beep.wav#L1",
    "libs/infinity_emb/tests/data/audio/cat_meow.wav#L1",
    "libs/infinity_emb/tests/data/benchmark/benchmark_embed_image.json#L1",
    "libs/infinity_emb/tests/data/benchmark/benchmark_embed.json#L1",
    "libs/infinity_emb/tests/data/datasets/stsbenchmark.tsv.gz#L1",
    "libs/infinity_emb/tests/end_to_end/__init__.py#L1",
    "libs/infinity_emb/tests/end_to_end/conftest.py#L1",
    "libs/infinity_emb/tests/end_to_end/test_api_with_dummymodel.py#L1",
    "libs/infinity_emb/tests/end_to_end/test_authentication.py#L1",
    "libs/infinity_emb/tests/end_to_end/test_authentication.py#L1-L80",
    "libs/infinity_emb/tests/end_to_end/test_ct2_sentence.py#L1",
    "libs/infinity_emb/tests/end_to_end/test_openapi_client_compat.py#L1",
    "libs/infinity_emb/tests/end_to_end/test_openapi_client_compat.py#L1-L120",
    "libs/infinity_emb/tests/end_to_end/test_optimum_embedding.py#L1",
    "libs/infinity_emb/tests/end_to_end/test_sentence_transformers_colbert.py#L1",
    "libs/infinity_emb/tests/end_to_end/test_sentence_transformers.py#L1",
    "libs/infinity_emb/tests/end_to_end/test_sentence_transformers.py#L1-L120",
    "libs/infinity_emb/tests/end_to_end/test_torch_audio.py#L1",
    "libs/infinity_emb/tests/end_to_end/test_torch_audio.py#L128-L220",
    "libs/infinity_emb/tests/end_to_end/test_torch_audio.py#L96-L192",
    "libs/infinity_emb/tests/end_to_end/test_torch_classify.py#L1",
    "libs/infinity_emb/tests/end_to_end/test_torch_reranker.py#L1",
    "libs/infinity_emb/tests/end_to_end/test_torch_vision.py#L1",
    "libs/infinity_emb/tests/end_to_end/test_torch_vision.py#L120-L196",
    "libs/infinity_emb/tests/end_to_end/test_torch_vision.py#L96-L176",
    "libs/infinity_emb/tests/install_test.sh#L1",
    "libs/infinity_emb/tests/script_live.py#L1",
    "libs/infinity_emb/tests/unit_test/fastapi_schemas/test_data_uri.py#L1",
    "libs/infinity_emb/tests/unit_test/fastapi_schemas/test_errors.py#L1",
    "libs/infinity_emb/tests/unit_test/fastapi_schemas/test_response.py#L1",
    "libs/infinity_emb/tests/unit_test/inference/test_batch_handler.py#L1",
    "libs/infinity_emb/tests/unit_test/inference/test_batch_handler.py#L1-L120",
    "libs/infinity_emb/tests/unit_test/inference/test_caching_layer.py#L1",
    "libs/infinity_emb/tests/unit_test/inference/test_models.py#L1",
    "libs/infinity_emb/tests/unit_test/inference/test_select_model.py#L1",
    "libs/infinity_emb/tests/unit_test/test_args.py#L1",
    "libs/infinity_emb/tests/unit_test/test_cli.py#L1",
    "libs/infinity_emb/tests/unit_test/test_engine.py#L1",
    "libs/infinity_emb/tests/unit_test/test_infinity_server.py#L1",
    "libs/infinity_emb/tests/unit_test/test_log_handler.py#L1",
    "libs/infinity_emb/tests/unit_test/test_sync_engine.py#L1",
    "libs/infinity_emb/tests/unit_test/transformer/audio/test_audio.py#L1",
    "libs/infinity_emb/tests/unit_test/transformer/classifier/test_optimum_classifier.py#L1",
    "libs/infinity_emb/tests/unit_test/transformer/classifier/test_torch_classifer.py#L1",
    "libs/infinity_emb/tests/unit_test/transformer/crossencoder/test_optimum_crossencoder.py#L1",
    "libs/infinity_emb/tests/unit_test/transformer/crossencoder/test_torch_crossencoder.py#L1",
    "libs/infinity_emb/tests/unit_test/transformer/embedder/test_optimum.py#L1",
    "libs/infinity_emb/tests/unit_test/transformer/embedder/test_torch.py#L1",
    "libs/infinity_emb/tests/unit_test/transformer/embedder/test_torch.py#L1-L80",
    "libs/infinity_emb/tests/unit_test/transformer/quantization/test_interface.py#L1",
    "libs/infinity_emb/tests/unit_test/transformer/test_utils.py#L1",
    "libs/infinity_emb/tests/unit_test/transformer/vision/test_torch_vision.py#L1",
    "libs/infinity_emb/tests/unit_test/transformer/vision/test_torch_vision.py#L1-L120",
    "LICENSE#L1",
    "LICENSE#L1-L40",
    "README.md#L1",
    "README.md#L1-L40",
    "README.md#L112-L148",
    "README.md#L112-L164",
    "README.md#L14-L76",
    "README.md#L14-L84",
    "README.md#L14-L86",
    "README.md#L16",
    "README.md#L18-L41",
    "README.md#L180-L236",
    "README.md#L196-L238",
    "README.md#L20-L38",
    "README.md#L242-L276",
    "README.md#L28-L40",
    "README.md#L42-L84",
    "README.md#L52-L80",
    "README.md#L88-L164",
    "README.md#L88-L176"
  ]
}
